{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Table of Contents\n",
    "<div class=\"toc\" style=\"margin-top: 1em;\">\n",
    "   <ul class=\"toc-item\" id=\"toc-level0\">\n",
    "      <li>\n",
    "         <span><a href=\"#API-Overview\" data-toc-modified-id=\"API-Overview-1\"><span class=\"toc-item-num\">1.&nbsp;&nbsp;</span>API Overview</a></span>\n",
    "         <ul class=\"toc-item\">\n",
    "            <li><span><a href=\"#Context\" data-toc-modified-id=\"Context-1.1\"><span class=\"toc-item-num\">1.1&nbsp;&nbsp;</span>Context</a></span></li>\n",
    "            <li><span><a href=\"#Creating-a-ClipperConnection\" data-toc-modified-id=\"Create-a-ClipperConnection-1.2\"><span class=\"toc-item-num\">1.2&nbsp;&nbsp;</span>Creating a ClipperConnection</a></span></li>\n",
    "            <li><span><a href=\"#Starting-Clipper\" data-toc-modified-id=\"Starting-Clipper-1.3\"><span class=\"toc-item-num\">1.3&nbsp;&nbsp;</span>Starting Clipper</a></span></li>\n",
    "            <li>\n",
    "               <span><a href=\"#Deploying-a-model\" data-toc-modified-id=\"Deploying-a-model-1.4\"><span class=\"toc-item-num\">1.4&nbsp;&nbsp;</span>Deploying a model</a></span>\n",
    "               <ul class=\"toc-item\">\n",
    "                  <li>\n",
    "                     <span><a href=\"#Creating-a-model\" data-toc-modified-id=\"Create-the-model-1.4.1\"><span class=\"toc-item-num\">1.4.1&nbsp;&nbsp;</span>Creating a model</a></span>\n",
    "                  </li>\n",
    "                  <li><span><a href=\"#Deploying-to-Clipper\" data-toc-modified-id=\"Deploying-to-Clipper-1.4.2\"><span class=\"toc-item-num\">1.4.2&nbsp;&nbsp;</span>Deploying to Clipper</a></span></li>\n",
    "                  <li><span><a href=\"#A-Note-About-Types-[Optional]\" data-toc-modified-id=\"A-Note-About-Types-[Optional]-1.4.3\"><span class=\"toc-item-num\">1.4.3&nbsp;&nbsp;</span>A Note About Types [Optional]</a></span></li>\n",
    "               </ul>\n",
    "            </li>\n",
    "            <li><span><a href=\"#Registering-an-Application\" data-toc-modified-id=\"Registering-an-Application-1.5\"><span class=\"toc-item-num\">1.5&nbsp;&nbsp;</span>Registering an Application</a></span></li>\n",
    "            <li><span><a href=\"#Inspecting-Clipper\" data-toc-modified-id=\"Inspecting-Clipper-1.6\"><span class=\"toc-item-num\">1.6&nbsp;&nbsp;</span>Inspecting Clipper</a></span></li>\n",
    "            <li><span><a href=\"#Updating-the-Model\" data-toc-modified-id=\"Updating-the-Model-1.7\"><span class=\"toc-item-num\">1.7&nbsp;&nbsp;</span>Updating the Model</a></span></li>\n",
    "            <li><span><a href=\"#Adding-Model-Replicas\" data-toc-modified-id=\"Adding-Model-Replicas-1.8\"><span class=\"toc-item-num\">1.8&nbsp;&nbsp;</span>Adding Model Replicas</a></span></li>\n",
    "         </ul>\n",
    "      </li>\n",
    "<li>\n",
    "         <span><a href=\"#Example-Application---Image-Classification\" data-toc-modified-id=\"Example-Application---Image-Classification\"><span class=\"toc-item-num\">2.&nbsp;&nbsp;</span>Example Application - Image Classification</a></span>\n",
    "      <li><span><a href=\"#Example-Application---Custom-Docker-Containers\" data-toc-modified-id=\"Example-Application---Custom-Docker-Containers\"><span class=\"toc-item-num\">3.&nbsp;&nbsp;</span>Example Application - Custom Docker Containers</a></span></li>\n",
    "      <li><span><a href=\"#Restarting-Clipper\" data-toc-modified-id=\"Restarting-Clipper\"><span class=\"toc-item-num\">4.&nbsp;&nbsp;</span>Restarting Clipper</a></span></li>\n",
    "   </ul>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='api_overview'></a>\n",
    "## API Overview\n",
    "\n",
    "In the first part of this exercise, you will explore how to create and interact with a Clipper cluster. The primary way of managing Clipper is with the Clipper Admin Python tool. This tutorial will walk you through all the things you can do with the Clipper Admin tool as well as explain what happens within Clipper when you issue each command. You can find the complete API documentation for the Clipper Admin tool on our website: <http://docs.clipper.ai>.\n",
    "\n",
    "**Goal:** Be familiar with how to create and manage a Clipper cluster, and understand what happens when you issue Clipper admin commands."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Context\n",
    "The Clipper Admin tool is distributed through Pip. You can install it with `pip install clipper_admin`, but it has already been installed in this notebook for you, in the first cell.\n",
    "\n",
    "Clipper is built on top of Docker containers. A running Clipper cluster consists of a collection of Docker containers communicating with each other over the network. As you issue commands against Clipper, you are communicating with these containers as well as creating new ones or destroying existing ones. As you explore the Clipper API throughout this exercise, we will illustrate how each command effects the cluster state.\n",
    "\n",
    "The main API for interacting with Clipper is exposed via a [`ClipperConnection`](http://docs.clipper.ai/en/develop/#clipper-connection) object. This is your handle to a Clipper cluster (this collection of Docker containers). It can be used to start, stop, inspect, and modify the cluster.\n",
    "\n",
    "In order to create a `ClipperConnection` object, you must provide it with a [`ContainerManager`](http://docs.clipper.ai/en/develop/#container-managers) object. While Docker is becoming an increasingly standard mechanism for deploying applications, there are many different tools for managing a Docker cluster. These tools broadly fall into the category of *Container Orchestration frameworks*. Some popular examples are [Kubernetes](https://kubernetes.io/), [Docker Swarm](https://docs.docker.com/engine/swarm/), and [DC/OS](https://dcos.io/). One of the reasons we run Clipper in Docker containers is to make the system as general as possible and support many different deployment scenarios. Within the Clipper Admin, we abstract away all of the Docker container-specific commands behind the `ContainerManager` interface. The `ClipperConnection` object makes Clipper-specific decisions about how to issue commands, and then makes any changes to the Docker configuration (for example, to launch a container for a newly deployed model) through the `ContainerManager`. To support different container orchestration frameworks that manage Docker containers in different ways, we create different implementations of the `ContainerManager` interface.\n",
    "\n",
    "Clipper currently provides two `ContainerManager` implementations: the `DockerContainerManager` and the `KubernetesContainerManager`. In this exercise, you will be using the `DockerContainerManager`, which runs Clipper directly on your local Docker instance. This `ContainerManager` is particularly useful for trying out Clipper without needing to set up an enterprise-grade container orchestration framework. The `DockerContainerManager` is not recommended for production use cases."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating a ClipperConnection\n",
    "To beginn using Clipper, we must first create a [`ClipperConnection`](http://docs.clipper.ai/en/develop/#clipper-connection) object. With the type of `ContainerManager` you want to use. It is important to note that creating a new connection object does not connect to Clipper - a good thing because there is no running Clipper instance to connect to!\n",
    "\n",
    "Before we connect, we need to start Clipper - which we will address in the next step.\n",
    "\n",
    "Returning to the process of creating a new connection object, we realize that the first step is to create a `DockerContainerManager` object. The `DockerContainerManager` constructor takes `docker_ip_address` as a keyword argument. Generally, since we want the Clipper cluster to be run locally, we can omit this argument, as its default value is `127.0.0.1`, which will suit our purposes in this case as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from clipper_admin import ClipperConnection, DockerContainerManager\n",
    "clipper_conn = ClipperConnection(DockerContainerManager())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Starting Clipper\n",
    "Now that we have a `ClipperConnection` object, we must start Clipper to provide it an endpoint to connect to.\n",
    "\n",
    "This command will start 3 Docker containers:\n",
    "1. The Query Frontend: The Query Frontend container listens for incoming prediction requests and schedules and routes them to the deployed models. In the future, it will also be able to call user defined model selection policies on prediction requests to decide which models to route to.\n",
    "2. The Management Frontend: The Management Frontend container manages and updates Clipper's internal configuration state.\n",
    "3. A Redis instance: Redis is used to persistently store Clipper's internal configuration state. Redis is started on port 6380 instead of the default port to avoid collisions with any Redis instances that are already running.\n",
    "\n",
    "The containers network together as illustrated below:\n",
    "![title](img/start_clipper.png)\n",
    "\n",
    "> *Because Docker must download the Docker images from the internet (if they are not already cached) before it can start the containers, the first time you run this command can take a long time to complete (up to a couple minutes) while the image is downloaded. Thanks for your patience.*\n",
    "\n",
    "If you try to start more than one Clipper cluster at once on the same host, the second execution of the command will fail because, by default, the second cluster will try to bind to the same ports as the first one. If you run into problems with the exercise and want to start over, see instructions on how to reset Clipper."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "18-09-09:00:07:28 INFO     [clipper_admin.py:1258] Stopped all Clipper cluster and all model containers\n"
     ]
    }
   ],
   "source": [
    "clipper_conn.stop_all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "18-09-09:00:07:28 INFO     [docker_container_manager.py:119] Starting managed Redis instance in Docker\n",
      "18-09-09:00:07:30 INFO     [clipper_admin.py:126] Clipper is running\n"
     ]
    }
   ],
   "source": [
    "clipper_conn.start_clipper()\n",
    "clipper_addr = clipper_conn.get_query_addr()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Deploying a model\n",
    "At its most basic, a trained model is just a function that takes some input and produces some output. As a result, one way to think about Clipper is as a function server. While these functions are often complex models, Clipper is not restricted to serving machine learning models.\n",
    "\n",
    "Deploying a model consists of two steps:\n",
    "1. Creating the model - Before a model can be deployed, it must first be written and trained.\n",
    "2. Deploying the model - Clipper offers a wide variety of deployers for standard ML packages to make deployment easier. In addition, it is possible to deploy packages such as XGBoost or Scikit-Learn using the default PythonClosureContainer, by specifying what packages to install, or to create your own model container.\n",
    "\n",
    "To start with, you will deploy a very simple model to Clipper. We'll start by clustering data with Scikit-Learn!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Creating a model\n",
    "We start by creating and training our model, which will be an 3 way classifier from sklearn.\n",
    "\n",
    "Complete the TODO's in the next cells to build our model!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'matplotlib'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-38-0bb3eb5fb13f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m# http://scikit-learn.org/stable/auto_examples/linear_model/plot_iris_logistic.html\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mlinear_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdatasets\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_line_magic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'matplotlib'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'inline'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'matplotlib'"
     ]
    }
   ],
   "source": [
    "# The code to train the model and produce the graph comes from this sklearn example:\n",
    "# http://scikit-learn.org/stable/auto_examples/linear_model/plot_iris_logistic.html\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import linear_model, datasets\n",
    "%matplotlib inline\n",
    "\n",
    "np.random.seed(5)\n",
    "\n",
    "iris = datasets.load_iris()\n",
    "X = iris.data[:, :2]  # We only take the first two features.\n",
    "Y = iris.target\n",
    "\n",
    "h = .02  # Step size in the mesh\n",
    "\n",
    "model = linear_model.LogisticRegression(C=1e5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Fit the model to the data (X) and the results (Y)\n",
    "# Toggle the visibility of the cell below for the answer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "model.fit(X, y)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-33-da659beb7734>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Plot the decision boundary. For that, we will assign a color to each\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m# point in the mesh [x_min, x_max]x[y_min, y_max].\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mx_min\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_max\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m.5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m.5\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0my_min\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_max\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m.5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m.5\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mxx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0myy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmeshgrid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_min\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_max\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_min\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_max\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'X' is not defined"
     ]
    }
   ],
   "source": [
    "# Plot the decision boundary. For that, we will assign a color to each\n",
    "# point in the mesh [x_min, x_max]x[y_min, y_max].\n",
    "x_min, x_max = X[:, 0].min() - .5, X[:, 0].max() + .5\n",
    "y_min, y_max = X[:, 1].min() - .5, X[:, 1].max() + .5\n",
    "xx, yy = np.meshgrid(np.arange(x_min, x_max, h), np.arange(y_min, y_max, h))\n",
    "Z = model.predict(np.c_[xx.ravel(), yy.ravel()])\n",
    "\n",
    "# Put the result into a color plot\n",
    "Z = Z.reshape(xx.shape)\n",
    "plt.figure(1, figsize=(4, 3))\n",
    "plt.pcolormesh(xx, yy, Z, cmap=plt.cm.Paired)\n",
    "\n",
    "# Plot also the training points\n",
    "plt.scatter(X[:, 0], X[:, 1], c=Y, edgecolors='k', cmap=plt.cm.Paired)\n",
    "plt.xlabel('Sepal length')\n",
    "plt.ylabel('Sepal width')\n",
    "\n",
    "plt.xlim(xx.min(), xx.max())\n",
    "plt.ylim(yy.min(), yy.max())\n",
    "plt.xticks(())\n",
    "plt.yticks(())\n",
    "plt.title('3 Way Classifier')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have a model, we need to create the function that we will deploy to Clipper. We know that our function takes an array of length 2 - a petal width and a sepal length - and returns a label, so we can just define our `predict_label` function as shown below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_label(flower):\n",
    "    if (len(flower) != 2):\n",
    "        return 'Invalid argument passed!'\n",
    "    return model.predict(flower)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To improve performance during inference, many machine learning models exploit opportunities for data parallelism in the inference process. Because of this, Clipper tries to provide multiple inputs at once to a deployed model. Therefore, models deployed to Clipper must have a function interface that takes a list of inputs as an argument and returns a list of predictions as strings. Returning predictions as strings provides a lot of flexibility over what your models can return. Commonly, models in Clipper will return either a single number (such as a label or score) or JSON containing a richer representation of the model output (for example, by including confidence estimates of predicted labels).\n",
    "\n",
    "Starting version 0.3.0, Clipper not only supports batching, but also performs adaptive batching. To perform adaptive batching, Clipper sends different batch sizes to models in order to determine which batch size is optimal, and therefore it is imperative to treat the input to the predict function as a batch. We will go into more detail about using batching with Clipper in a later section.\n",
    "\n",
    "We redefine our `predict_label` function, this time calling it `predict_flower`, to support this API. Since we are returning a string anyways, we might as well convert the labels given to us by our model to the corresponding flower name."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-41-22bd72a1fc67>, line 4)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-41-22bd72a1fc67>\"\u001b[0;36m, line \u001b[0;32m4\u001b[0m\n\u001b[0;31m    labels =\u001b[0m\n\u001b[0m             ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "def predict_flower(flowers):\n",
    "    # TODO: Use the model to get predictions\n",
    "    # Toggle the next cell's visibility to see the solution.\n",
    "    labels = \n",
    "    return ['Setosa' if l == 0 else 'Versicolour' if l == 2 else 'Virginica' for l in labels]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "def predict_flower(flowers):\n",
    "    # TODO: Use the model to get predictions\n",
    "    # Toggle the next cell's visibility to see the solution.\n",
    "    labels = model.predict(flowers)\n",
    "    return ['Setosa' if l == 0 else 'Versicolour' if l == 2 else 'Virginica' for l in labels]\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have a valid function, we proceed to the deployment stage!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Just a quick test\n",
    "assert predict_flower([X[0], X[101]]) == ['Setosa', 'Virginica']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Deploying to Clipper"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One of the goals of Clipper is to make it simple to deploy and maintain machine-learning models in production. The prediction interface that models must implement is very simple, consisting of a single function. And the use of Docker makes it easy to include all of a model's dependencies in a self-contained environment. However, deploying a new type of model still entails writing and debugging a new model container and creating a Docker image.\n",
    "To make the model deployment process even simpler, Clipper provides a library of model deployers for common types of models. If your model can be deployed with one of these deployers, you no longer need to write a model container, create a Docker image, or even figure out how to save a model. Instead, you provide your trained model directly to the model deployer function within your Python process. The model deployer takes care of saving the model and building a Docker image that is compatible with your model type.\n",
    "\n",
    "Clipper provides model deployers for many common ML packages including PySpark, ONNX, TensorFlow, etc. In addition, Clipper provides a model deployer (the `PythonClosureContainer`) that can deploy arbitrary Python functions, and the ability to write custom containers for unsupported models.\n",
    "\n",
    "To keep the base images light, Clipper model containers install only the required dependencies to ensure that a basic model will run. Starting in version 0.3.0, users are also offered the ability to specify packages to install via pip on new model containers during their startup using the `pkgs_to_install` keyword argument. This feature is in all model containers, and today, we will use it with the `PythonClosureContainer` to deploy our Scikit-Learn model.\n",
    "\n",
    "Some models, such as those provided by Scikit-Learn or XGBoost, can be pickled, and require only that the packages are installed, and so these models can be deployed using the `PythonClosureContainer` and specifying that the packages are installed via the `pkgs_to_install` keyword argument, rather than creating custom model deployment containers.\n",
    "\n",
    "For more information about model deployers, check out the docs on our [site](http://clipper.ai)!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'predict_flower' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-42-13b10c3c2702>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mversion\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0;31m# A unique identifier to assign to this model.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0minput_type\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"floats\"\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0;31m# The type of data the model function expects as input\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m     \u001b[0mfunc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpredict_flower\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;31m# The model function to deploy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m     \u001b[0mpkgs_to_install\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'numpy'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'scipy'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'scikit-learn'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;31m# Packages to install in the new container. Must be a list\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m )\n",
      "\u001b[0;31mNameError\u001b[0m: name 'predict_flower' is not defined"
     ]
    }
   ],
   "source": [
    "from clipper_admin.deployers import python as python_deployer\n",
    "python_deployer.deploy_python_closure(\n",
    "    clipper_conn,\n",
    "    name=\"flowercat\",  # The name of the model in Clipper\n",
    "    version=1,  # A unique identifier to assign to this model.\n",
    "    input_type=\"floats\",  # The type of data the model function expects as input\n",
    "    func=predict_flower, # The model function to deploy\n",
    "    pkgs_to_install=['numpy', 'scipy', 'scikit-learn'] # Packages to install in the new container. Must be a list\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Clipper deploys each model in its own Docker container. After deploying the model, Clipper uses the DockerContainerManager to start a container for this model and create an RPC connection with the Clipper query frontend, as illustrated below (the changes to the cluster are highlighted in red).\n",
    "\n",
    "> *Once again, Clipper must download a Docker container from the internet the first time this command is run.*\n",
    "\n",
    "![title](img/deploy_model.png)\n",
    "\n",
    "If you list the Clipper containers again, you can see the container running your word count model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CONTAINER ID        IMAGE                               COMMAND                  CREATED             STATUS              PORTS                                            NAMES\n",
      "35e7a5bd9a5e        prom/prometheus:v2.1.0              \"/bin/prometheus --c…\"   10 minutes ago      Up 10 minutes       0.0.0.0:9090->9090/tcp                           metric_frontend-55202\n",
      "6ffc888cb3f6        clipper/frontend-exporter:0.3.0     \"python /usr/src/app…\"   10 minutes ago      Up 10 minutes                                                        query_frontend_exporter-42083\n",
      "8fc68fc2df95        clipper/query_frontend:0.3.0        \"/clipper/release/sr…\"   10 minutes ago      Up 10 minutes       0.0.0.0:1337->1337/tcp, 0.0.0.0:7000->7000/tcp   query_frontend-42083\n",
      "929dbb7462c2        clipper/management_frontend:0.3.0   \"/clipper/release/sr…\"   10 minutes ago      Up 10 minutes       0.0.0.0:1338->1338/tcp                           mgmt_frontend-6587\n",
      "27e6261559fd        redis:alpine                        \"docker-entrypoint.s…\"   10 minutes ago      Up 10 minutes       0.0.0.0:6379->6379/tcp                           redis-48375\n"
     ]
    }
   ],
   "source": [
    "!docker ps --filter label=ai.clipper.container.label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### A Note About Types [Optional]\n",
    "When you deploy models and register applications, you must specify the input type that the model or application expects. The type that you specify has implications for how Clipper manages input serialization and deserialization. From the user's perspective, the input type affects the behavior of Clipper in two places. In the \"input\" field of the request JSON body, applications will reject requests where the value of that field is the wrong type. And the deployed model function will be called with a list of inputs of the specified type.\n",
    "\n",
    "The input type can be one of the following types:\n",
    "\n",
    "* \"ints\": The value of the \"input\" field in a request must be a JSON list of ints. The model function will be called with a list of numpy arrays of type numpy.int.\n",
    "* \"floats\": The value of the \"input\" field in a request must be a JSON list of doubles. The model function will be called with a list of numpy arrays of type numpy.float32.\n",
    "* \"doubles\": The value of the \"input\" field in a request must be a JSON list of doubles. The model function will be called with a list of numpy arrays of type numpy.float64.\n",
    "* \"bytes\": The value of the \"input\" field in a request must be a Base64 encoded string. The model function will be called with a list of numpy arrays of type numpy.int8.\n",
    "* \"strings\": The value of the \"input\" field in a request must be a string. The model function will be called with a list of strings."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Registering an Application\n",
    "You've now deployed a model to Clipper, but you don't have any way to query it yet. Instead of automatically creating a REST endpoint when you deploy a model, Clipper introduces a layer of indirection: the application. Clients query a specific application in Clipper, and the application routes the query to the correct model. This allows multiple applications to route queries to the same model, and allows a single application to route queries to multiple models.\n",
    "\n",
    "A single Clipper cluster can have many applications registered and many models deployed at once.\n",
    "\n",
    "When you register an application you configure certain elements of the application's behavior. These include:\n",
    "\n",
    "* The name to give the REST endpoint.\n",
    "* The input type that the application expects (Clipper will ensure applications only route requests to models with matching input types).\n",
    "* The latency service level objective (SLO) specified in microseconds. Clipper will manage how it schedules and routes queries for an application based on the specified service level objective. For example, Clipper will set the amount of time it allows requests to spend queued before being sent to the model based on the service level objective for the application requesting the prediction. In addition, Clipper will respond to requests by the end of the specified SLO, even if it has not received a prediction back from the model.\n",
    "* The default output: Clipper will respond with the default output to requests if a real prediction isn't available by the end of the service level objective.\n",
    "* (In the future) The selection policy: The default or user defined model selection policy to use when determining which models to route requests to.\n",
    "\n",
    "When you register an application with Clipper, it creates a REST endpoint for that application:\n",
    "\n",
    "```\n",
    "URL: /<app_name>/predict\n",
    "Method: POST\n",
    "Data Params: {\"input\": <input>}\n",
    "```\n",
    "\n",
    "To provide batch requests to clipper, you simply substitute `input` with `input_batch`. If both appear, `input` will be used, and `input_batch` ignored.\n",
    "\n",
    "```\n",
    "URL: /<app_name>/predict\n",
    "Method: POST\n",
    "Data Params: {\"input_batch\": <input_batch>}\n",
    "```\n",
    "\n",
    "![title](img/register_app.png)\n",
    "\n",
    "Register an application to query your classifier:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "18-09-09:00:17:41 INFO     [clipper_admin.py:201] Application flowercat-app was successfully registered\n"
     ]
    }
   ],
   "source": [
    "clipper_conn.register_application(\n",
    "    name=\"flowercat-app\",\n",
    "    input_type=\"floats\",\n",
    "    default_output=\"Default\",\n",
    "    slo_micros=100000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Try querying the newly created application. We use Python in this example, but it can also be done with [curl](https://curl.haxx.se)!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-45-213d9ab25833>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m      \u001b[0mheaders\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m\"Content-type\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m\"application/json\"\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m      data=json.dumps({\n\u001b[0;32m----> 6\u001b[0;31m          \u001b[0;34m'input'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m      }))\n\u001b[1;32m      8\u001b[0m \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjson\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'X' is not defined"
     ]
    }
   ],
   "source": [
    "import requests, json\n",
    "response = requests.post(\n",
    "     \"http://%s/%s/predict\" % (clipper_addr, 'flowercat-app'),\n",
    "     headers={\"Content-type\": \"application/json\"},\n",
    "     data=json.dumps({\n",
    "         'input': list(X[0]),\n",
    "     }))\n",
    "result = response.json()\n",
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You should see that your application returned the default output of \"Default\". This is because even though you have deployed a model and registered an application, you have not told Clipper to route requests from the \"flowercat-app\" application to the \"flowercat\" model.\n",
    "\n",
    "You do this by linking the model to the application.\n",
    "\n",
    "![title](img/link_model.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "18-09-09:00:17:42 ERROR    [clipper_admin.py:258] Received error status code: 400 and message: No model with name 'flowercat' exists.\n"
     ]
    },
    {
     "ename": "ClipperException",
     "evalue": "Received error status code: 400 and message: No model with name 'flowercat' exists.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mClipperException\u001b[0m                          Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-46-5c5ebb4d983d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mclipper_conn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlink_model_to_app\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mapp_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"flowercat-app\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"flowercat\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/miniconda3/lib/python3.6/site-packages/clipper_admin/clipper_admin.py\u001b[0m in \u001b[0;36mlink_model_to_app\u001b[0;34m(self, app_name, model_name)\u001b[0m\n\u001b[1;32m    257\u001b[0m                 code=r.status_code, msg=r.text)\n\u001b[1;32m    258\u001b[0m             \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merror\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 259\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mClipperException\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    260\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    261\u001b[0m             logger.info(\n",
      "\u001b[0;31mClipperException\u001b[0m: Received error status code: 400 and message: No model with name 'flowercat' exists."
     ]
    }
   ],
   "source": [
    "clipper_conn.link_model_to_app(app_name=\"flowercat-app\", model_name=\"flowercat\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When you query the \"wordcount-app\" endpoint again, Clipper should return the correct word count. Try it with your own input. Toggle the visibility of the cell after for an example!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-47-2c7b9fa60500>, line 5)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-47-2c7b9fa60500>\"\u001b[0;36m, line \u001b[0;32m5\u001b[0m\n\u001b[0;31m    'input': , # TODO: Specify an input\u001b[0m\n\u001b[0m             ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "response = requests.post(\n",
    "     \"http://%s/%s/predict\" % (clipper_addr, 'flowercat-app'),\n",
    "     headers={\"Content-type\": \"application/json\"},\n",
    "     data=json.dumps({\n",
    "         'input': , # TODO: Specify an input\n",
    "     }))\n",
    "result = response.json()\n",
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "response = requests.post(\n",
    "     \"http://%s/%s/predict\" % (clipper_addr, 'flowercat-app'),\n",
    "     headers={\"Content-type\": \"application/json\"},\n",
    "     data=json.dumps({\n",
    "         'input': list(X[0]), # TODO: Specify an input\n",
    "     }))\n",
    "result = response.json()\n",
    "result\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inspecting Clipper\n",
    "The ClipperConnection object has several methods to inspect various aspects of the Clipper cluster.\n",
    "\n",
    "You can list all of the applications."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'input_type': 'floats',\n",
       "  'default_output': 'Default',\n",
       "  'latency_slo_micros': 100000,\n",
       "  'name': 'flowercat-app',\n",
       "  'linked_models': []}]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clipper_conn.get_all_apps(verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Or all of the models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clipper_conn.get_all_models(verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Clipper also tracks several performance metrics that you can inspect at any time, as well as allows you to deploy your own custom metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'counters': [{'internal:prediction_cache_lookups': {'count': '0'}},\n",
       "  {'internal:aggregate_num_predictions': {'count': '0'}},\n",
       "  {'app:flowercat-app:num_predictions': {'count': '0'}}],\n",
       " 'ratio_counters': [{'internal:prediction_cache_hit_ratio': {'ratio': 'nan'}},\n",
       "  {'app:flowercat-app:default_prediction_ratio': {'ratio': 'nan'}}],\n",
       " 'meters': [{'internal:aggregate_model_throughput': {'unit': 'events per second',\n",
       "    'rate': '0',\n",
       "    'rate_1min': '0',\n",
       "    'rate_5min': '0',\n",
       "    'rate_15min': '0'}},\n",
       "  {'app:flowercat-app:prediction_throughput': {'unit': 'events per second',\n",
       "    'rate': '0',\n",
       "    'rate_1min': '0',\n",
       "    'rate_5min': '0',\n",
       "    'rate_15min': '0'}}],\n",
       " 'histograms': [{'internal:rpc_request_queueing_delay': {'unit': 'microseconds',\n",
       "    'size': '0',\n",
       "    'min': '0',\n",
       "    'max': '0',\n",
       "    'mean': '0',\n",
       "    'std_dev': '0',\n",
       "    'p50': '0',\n",
       "    'p95': '0',\n",
       "    'p99': '0'}},\n",
       "  {'app:flowercat-app:prediction_latency': {'unit': 'microseconds',\n",
       "    'size': '0',\n",
       "    'min': '0',\n",
       "    'max': '0',\n",
       "    'mean': '0',\n",
       "    'std_dev': '0',\n",
       "    'p50': '0',\n",
       "    'p95': '0',\n",
       "    'p99': '0'}}]}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clipper_conn.inspect_instance()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can also fetch the raw container logs from all of the Clipper docker containers. The command will print the paths to the log files for further examination. You can figure out which logs belong to which container based on the unique Docker container ID in the log filename."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/home/ubuntu/clipper-tutorials/clipper_logs/image_sha256:c8ecf7c719:container_35e7a5bd9a.log',\n",
       " '/home/ubuntu/clipper-tutorials/clipper_logs/image_sha256:c29b40eb63:container_6ffc888cb3.log',\n",
       " '/home/ubuntu/clipper-tutorials/clipper_logs/image_sha256:7eefa1a263:container_8fc68fc2df.log',\n",
       " '/home/ubuntu/clipper-tutorials/clipper_logs/image_sha256:3d960da25d:container_929dbb7462.log',\n",
       " '/home/ubuntu/clipper-tutorials/clipper_logs/image_sha256:162794862d:container_27e6261559.log']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clipper_conn.get_clipper_logs()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Updating the Model\n",
    "Machine learning models are rarely static. Instead, data science tends to be an iterative process, with new and improved models being developed over time. Clipper supports this workflow by letting you deploy new versions of models. If you look back to where you linked your flowercat model to the application, you'll see that there is no mention of versioning in that method call. Instead, when a new version of a model is deployed, Clipper will automatically start routing requests to the new version.\n",
    "\n",
    "Create a new version of the \"flowercat\" model that returns the probabilities that an input is in each class instead."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def new_predict_flower(flowers):\n",
    "    # TODO: Return a prediction\n",
    "    return "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Click the cell below for the answer!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "def new_predict_flower(flowers):\n",
    "    # TODO: Return a prediction\n",
    "    return model.predict_proba(flowers)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-15-c3d52d35ebaf>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mnew_predict_flower\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'X' is not defined"
     ]
    }
   ],
   "source": [
    "new_predict_flower([X[0]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Deploy this new version of the function as version \"2\". For this application, you are using a numeric versioning scheme. But Clipper just treats versions as unique string identifiers, so you could use other versioning schemes (such as Git hashes or semantic versioning). Versions don't even have to be ordered, Clipper just tracks the currently active version.\n",
    "\n",
    "![title](img/update_model.png)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'python_deployer' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-16-f298a89addf0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m python_deployer.deploy_python_closure(\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0mclipper_conn\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"flowercat\"\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0;31m# The name of the model in Clipper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mversion\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0;31m# A unique identifier to assign to this model.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0minput_type\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"floats\"\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0;31m# The type of data the model function expects as input\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'python_deployer' is not defined"
     ]
    }
   ],
   "source": [
    "python_deployer.deploy_python_closure(\n",
    "    clipper_conn,\n",
    "    name=\"flowercat\",  # The name of the model in Clipper\n",
    "    version=2,  # A unique identifier to assign to this model.\n",
    "    input_type=\"floats\",  # The type of data the model function expects as input\n",
    "    func=new_predict_flower, # The model function to deploy\n",
    "    pkgs_to_install=['numpy', 'scipy', 'scikit-learn'] # Packages to install in the new container. Must be a list\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-17-b4735e2cb390>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m      \u001b[0mheaders\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m\"Content-type\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m\"application/json\"\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m      data=json.dumps({\n\u001b[0;32m----> 5\u001b[0;31m          \u001b[0;34m'input'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m      }))\n\u001b[1;32m      7\u001b[0m \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjson\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'X' is not defined"
     ]
    }
   ],
   "source": [
    "response = requests.post(\n",
    "     \"http://%s/%s/predict\" % (clipper_addr, 'flowercat-app'),\n",
    "     headers={\"Content-type\": \"application/json\"},\n",
    "     data=json.dumps({\n",
    "         'input': list(X[0]),\n",
    "     }))\n",
    "result = response.json()\n",
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sometimes the \"new and improved\" model is not actually improved. If you deploy a model that isn't working well, you can roll back to any previous version. This just changes which version of the model application's route requests to.\n",
    "\n",
    "![title](img/rollback_version.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "18-09-09:00:08:04 ERROR    [clipper_admin.py:1121] Received error status code: 400 and message: Cannot set version for nonexistent model 'flowercat'\n"
     ]
    },
    {
     "ename": "ClipperException",
     "evalue": "Received error status code: 400 and message: Cannot set version for nonexistent model 'flowercat'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mClipperException\u001b[0m                          Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-18-d7228648e8ae>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mclipper_conn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_model_version\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"flowercat\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mversion\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"1\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/miniconda3/lib/python3.6/site-packages/clipper_admin/clipper_admin.py\u001b[0m in \u001b[0;36mset_model_version\u001b[0;34m(self, name, version, num_replicas)\u001b[0m\n\u001b[1;32m   1120\u001b[0m                 code=r.status_code, msg=r.text)\n\u001b[1;32m   1121\u001b[0m             \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merror\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1122\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mClipperException\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1123\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1124\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mnum_replicas\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mClipperException\u001b[0m: Received error status code: 400 and message: Cannot set version for nonexistent model 'flowercat'"
     ]
    }
   ],
   "source": [
    "clipper_conn.set_model_version(name=\"flowercat\", version=\"1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-19-b4735e2cb390>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m      \u001b[0mheaders\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m\"Content-type\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m\"application/json\"\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m      data=json.dumps({\n\u001b[0;32m----> 5\u001b[0;31m          \u001b[0;34m'input'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m      }))\n\u001b[1;32m      7\u001b[0m \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjson\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'X' is not defined"
     ]
    }
   ],
   "source": [
    "response = requests.post(\n",
    "     \"http://%s/%s/predict\" % (clipper_addr, 'flowercat-app'),\n",
    "     headers={\"Content-type\": \"application/json\"},\n",
    "     data=json.dumps({\n",
    "         'input': list(X[0]),\n",
    "     }))\n",
    "result = response.json()\n",
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adding Model Replicas\n",
    "Many machine learning models are computationally expensive and a single instance of the model may not meet the throughput demands of a serving workload. To increase prediction throughput, you can add additional replicas of a model. This creates additional Docker containers running the same model. Clipper will act as a load-balancer and distribute incoming requests across the set of available model replicas to provide higher throughput.\n",
    "\n",
    "Set the number of replicas for the currently active version (\"1\") of the \"wordcount\" model to 4.\n",
    "\n",
    "![title](img/add_replicas.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "ClipperException",
     "evalue": "No versions of model flowercat registered with Clipper",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mClipperException\u001b[0m                          Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-20-07b7a859d0b4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mclipper_conn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_num_replicas\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"flowercat\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_replicas\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/miniconda3/lib/python3.6/site-packages/clipper_admin/clipper_admin.py\u001b[0m in \u001b[0;36mset_num_replicas\u001b[0;34m(self, name, num_replicas, version)\u001b[0m\n\u001b[1;32m    721\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mUnconnectedException\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    722\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mversion\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 723\u001b[0;31m             \u001b[0mversion\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_current_model_version\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    724\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    725\u001b[0m             \u001b[0mversion\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mversion\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.6/site-packages/clipper_admin/clipper_admin.py\u001b[0m in \u001b[0;36mget_current_model_version\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m    664\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mversion\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    665\u001b[0m             raise ClipperException(\n\u001b[0;32m--> 666\u001b[0;31m                 \"No versions of model {} registered with Clipper\".format(name))\n\u001b[0m\u001b[1;32m    667\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mversion\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    668\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mClipperException\u001b[0m: No versions of model flowercat registered with Clipper"
     ]
    }
   ],
   "source": [
    "clipper_conn.set_num_replicas(\"flowercat\", num_replicas=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you list the Clipper Docker containers, you should now see four containers based on the image \"flowercat:1\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CONTAINER ID        IMAGE                               COMMAND                  CREATED             STATUS              PORTS                                            NAMES\n",
      "35e7a5bd9a5e        prom/prometheus:v2.1.0              \"/bin/prometheus --c…\"   40 seconds ago      Up 38 seconds       0.0.0.0:9090->9090/tcp                           metric_frontend-55202\n",
      "6ffc888cb3f6        clipper/frontend-exporter:0.3.0     \"python /usr/src/app…\"   40 seconds ago      Up 39 seconds                                                        query_frontend_exporter-42083\n",
      "8fc68fc2df95        clipper/query_frontend:0.3.0        \"/clipper/release/sr…\"   40 seconds ago      Up 39 seconds       0.0.0.0:1337->1337/tcp, 0.0.0.0:7000->7000/tcp   query_frontend-42083\n",
      "929dbb7462c2        clipper/management_frontend:0.3.0   \"/clipper/release/sr…\"   41 seconds ago      Up 40 seconds       0.0.0.0:1338->1338/tcp                           mgmt_frontend-6587\n",
      "27e6261559fd        redis:alpine                        \"docker-entrypoint.s…\"   41 seconds ago      Up 40 seconds       0.0.0.0:6379->6379/tcp                           redis-48375\n"
     ]
    }
   ],
   "source": [
    "!docker ps --filter label=ai.clipper.container.label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you want to reduce the number of replicas of a model to free up hardware resource, you can use the same command.\n",
    "\n",
    "Set the number of replicas for \"flowercat\" back to 1.\n",
    "\n",
    "![title](img/set_replicas.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-22-ddb0d26237d2>, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-22-ddb0d26237d2>\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    clipper_conn.set_num_replicas(\"flowercat\", num_replicas=)\u001b[0m\n\u001b[0m                                                            ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "clipper_conn.set_num_replicas(\"flowercat\", num_replicas=)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CONTAINER ID        IMAGE                               COMMAND                  CREATED             STATUS              PORTS                                            NAMES\n",
      "35e7a5bd9a5e        prom/prometheus:v2.1.0              \"/bin/prometheus --c…\"   48 seconds ago      Up 46 seconds       0.0.0.0:9090->9090/tcp                           metric_frontend-55202\n",
      "6ffc888cb3f6        clipper/frontend-exporter:0.3.0     \"python /usr/src/app…\"   48 seconds ago      Up 47 seconds                                                        query_frontend_exporter-42083\n",
      "8fc68fc2df95        clipper/query_frontend:0.3.0        \"/clipper/release/sr…\"   48 seconds ago      Up 47 seconds       0.0.0.0:1337->1337/tcp, 0.0.0.0:7000->7000/tcp   query_frontend-42083\n",
      "929dbb7462c2        clipper/management_frontend:0.3.0   \"/clipper/release/sr…\"   49 seconds ago      Up 48 seconds       0.0.0.0:1338->1338/tcp                           mgmt_frontend-6587\n",
      "27e6261559fd        redis:alpine                        \"docker-entrypoint.s…\"   49 seconds ago      Up 48 seconds       0.0.0.0:6379->6379/tcp                           redis-48375\n"
     ]
    }
   ],
   "source": [
    "!docker ps --filter label=ai.clipper.container.label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example Application - Image Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the second part of this exercise, you will deploy a SqueezeNet model, using PyTorch, that uses computer vision models to classify images.\n",
    "\n",
    "You will create an application that labels images from the ImageNet dataset.\n",
    "\n",
    "These images have already been downloaded for you within the directory."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating an application\n",
    "\n",
    "For this tutorial, create an application named \"squeezenet-classifier\". Note that Clipper allows you to create the application before deploying any models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "18-09-09:00:08:42 INFO     [clipper_admin.py:201] Application squeezenet-classsifier was successfully registered\n"
     ]
    }
   ],
   "source": [
    "app_name = \"squeezenet-classsifier\"\n",
    "# If the model (which we will later link to our application) doesn't\n",
    "# return a prediction in time, we will return \"default\" as our prediction.\n",
    "default_output = \"default\"\n",
    "\n",
    "clipper_conn.register_application(\n",
    "    name=app_name,\n",
    "    input_type=\"bytes\",\n",
    "    default_output=default_output,\n",
    "    slo_micros=10000000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When you list the applications registered with Clipper, you should see the newly registered \"squeezenet-classifier\" application show up!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['squeezenet-classsifier', 'squeezenet-classsifier-2', 'flowercat-app']"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clipper_conn.get_all_apps()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Start serving\n",
    "\n",
    "Now that you have registered an application, you can start querying the application for predictions. \n",
    "\n",
    "We will hold off on doing this until we deploy the corresponding model container though."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load our PyTorch Model\n",
    "\n",
    "Let's now deploy our pretrained SqueezeNet model.\n",
    "\n",
    "First we have to load it using the `torchvision` API."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'torchvision'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-28-8f69290f46dc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtorchvision\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmodels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtransforms\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;31m# We set the pretrained flag to True to get a trained model.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqueezenet1_1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpretrained\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'torchvision'"
     ]
    }
   ],
   "source": [
    "from torchvision import models, transforms\n",
    "# We set the pretrained flag to True to get a trained model.\n",
    "model = models.squeezenet1_1(pretrained=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Deploying our PyTorch Model\n",
    "\n",
    "Unlike the Scikit-Learn model in [Section 1](#API-Overview), PyTorch models cannot just be pickled and loaded. Instead, they must be saved using PyTorch's native serialization API. Because of this, you cannot use the generic Python model deployer to deploy the model to Clipper. Instead, we must use the Clipper PyTorch deployer to deploy it. The Docker container will load and reconstruct the model from the serialized model checkpoint when the container is started.\n",
    "\n",
    "After completing this step and deploying the new model, Clipper will send queries to the newly-deployed PyTorch model.\n",
    "\n",
    "> *Once again, Clipper must download this Docker image from the internet, so this may take a minute. Thanks for your patience.*\n",
    "\n",
    "We'll start by creating a predict function. Before we get into it, though, let us discuss metrics."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Metrics\n",
    "Pay special attention to the metrics - this is a new feature within Clipper. Clipper, by default, provides certain metrics, such as batch size, but it is also possible to add user metrics. Clipper uses Prometheus to track these metrics, and so the dashboard can be seen at http://localhost:9090/. It is also easy to connect this to Grafana, something that has been done for you in this tutorial. For this example, we will add a variable that tracks the average batch size to illustrate Clipper's adaptive batching."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Preprocessing\n",
    "Before making the predict function, we must dowload the labels for the dataset, and specify preprocessing on the images. The code for this cell comes from the this [tutorial](http://blog.outcome.io/pytorch-quick-start-classifying-an-image/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'transforms' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-29-17c4031c6615>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# First we define the preproccessing on the images:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m normalize = transforms.Normalize(\n\u001b[0m\u001b[1;32m      3\u001b[0m    \u001b[0mmean\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0.485\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.456\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.406\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m    \u001b[0mstd\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0.229\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.224\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.225\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m )\n",
      "\u001b[0;31mNameError\u001b[0m: name 'transforms' is not defined"
     ]
    }
   ],
   "source": [
    "# First we define the preproccessing on the images:\n",
    "normalize = transforms.Normalize(\n",
    "   mean=[0.485, 0.456, 0.406],\n",
    "   std=[0.229, 0.224, 0.225]\n",
    ")\n",
    "preprocess = transforms.Compose([\n",
    "   transforms.Scale(256),\n",
    "   transforms.CenterCrop(224),\n",
    "   transforms.ToTensor(),\n",
    "   normalize\n",
    "])\n",
    "\n",
    "# Then we download the labels:\n",
    "labels = {int(key):value for (key, value)\n",
    "          in requests.get('https://s3.amazonaws.com/outcome-blog/imagenet/labels.json').json().items()}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predict function\n",
    "Now we must define a predit function to deploy. We send each image as bytes, so we must first deserialize the image before we can perform any operations on it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import clipper_admin.metrics as metrics\n",
    "\n",
    "def predict_torch_model(n, imgs):\n",
    "    import base64\n",
    "    import io\n",
    "    import os\n",
    "    import PIL.Image\n",
    "    import tempfile\n",
    "    import torch\n",
    "    metrics.add_metric(\"batch_size\", 'Gauge', 'Batch size passed to PyTorch predict function.')\n",
    "    metrics.report_metric('batch_size', len(imgs))\n",
    "    \n",
    "    img_tensors = []\n",
    "    for img in imgs:\n",
    "        # Create a temp file to write to\n",
    "        tmp = tempfile.NamedTemporaryFile('wb', delete=False, suffix='.jpg')\n",
    "        tmp.write(io.BytesIO(img).getvalue())\n",
    "        tmp.close()\n",
    "        \n",
    "        # Pre-process image\n",
    "        img_tensor = preprocess(PIL.Image.open(tmp.name, 'r'))\n",
    "        img_tensor.unsqueeze_(0)\n",
    "        img_tensors.append(img_tensor)\n",
    "        \n",
    "        os.unlink(tmp.name) \n",
    "        \n",
    "        # Pass image to model\n",
    "    img_batch = torch.cat(img_tensors)\n",
    "    with torch.no_grad():\n",
    "        fc_out = n(img_batch)\n",
    "        \n",
    "        # Parse Result\n",
    "    img_labs = [labels[out.data.numpy().argmax()] for out in fc_out]\n",
    "        \n",
    "        # Delete Temp File\n",
    "        \n",
    "    return img_labs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-31-55291b3165e2>, line 4)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-31-55291b3165e2>\"\u001b[0;36m, line \u001b[0;32m4\u001b[0m\n\u001b[0;31m    name= , # TODO: Give model a name\u001b[0m\n\u001b[0m          ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "from clipper_admin.deployers import pytorch as pytorch_deployer\n",
    "pytorch_deployer.deploy_pytorch_model(\n",
    "    clipper_conn,\n",
    "    name= , # TODO: Give model a name \n",
    "    version=1, \n",
    "    input_type=\"bytes\", \n",
    "    func=predict_torch_model,\n",
    "    pytorch_model= , # TODO: Pass model to function\n",
    "    base_image='clipper/pytorch36-container:3c5a1cc6ce'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Toggle the visibility on the next cell for the correct answer!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "from clipper_admin.deployers import pytorch as pytorch_deployer\n",
    "pytorch_deployer.deploy_pytorch_model(\n",
    "    clipper_conn,\n",
    "    name= \"pytorch-model\", # TODO: Give model a name \n",
    "    version=1, \n",
    "    input_type=\"bytes\", \n",
    "    func=predict_torch_model,\n",
    "    pytorch_model= model, # TODO: Pass model to function\n",
    "    base_image='clipper/pytorch36-container:3c5a1cc6ce'\n",
    ")\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "18-09-07:02:32:39 INFO     [clipper_admin.py:263] Model pytorch-model is now linked to application squeezenet-classsifier-2\n"
     ]
    }
   ],
   "source": [
    "clipper_conn.link_model_to_app(app_name=\"squeezenet-classsifier-2\", model_name=\"pytorch-model\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to initialize Grafana and connect it to Clipper's Prometheus container, we run the following file, which will start up a Grafana container, and then connect it to Clipper's Prometheus interface, specifying it as a data source:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1/3) Initializing Grafana\n",
      "^C\n",
      "Stopping Grafana...\n"
     ]
    }
   ],
   "source": [
    "!python init_grafana.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "import base64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'query_id': 10, 'output': 'tabby, tabby cat', 'default': False}"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import requests, json\n",
    "req_json = json.dumps({\n",
    "        \"input\":\n",
    "        base64.b64encode(open('images/cat.jpg', \"rb\").read()).decode() # bytes to unicode\n",
    "    })\n",
    "\n",
    "response = requests.post(\n",
    "     \"http://%s/%s/predict\" % (clipper_addr, 'squeezenet-classsifier-2'),\n",
    "     headers={\"Content-type\": \"application/json\"},\n",
    "     data=req_json)\n",
    "response.json()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It's important to note that since we are sending requests in series, there aren't multiple requests in the system at any one time, and therefore, the system will not experience natural batching. We will still observe batching; however, thanks to Clipper's batching exploration algorithm, which adaptively batches requests in order to find the batch size that maximizes throughput and utilization while still meeting the latency SLO for a specific model container."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "images = ['images/cat.jpg', 'images/dog.jpg']\n",
    "for img in images:\n",
    "    print('Output for', img)\n",
    "    req_json = json.dumps({\n",
    "            \"input\":\n",
    "            base64.b64encode(open(img, \"rb\").read()).decode() # bytes to unicode\n",
    "        })\n",
    "\n",
    "    response = requests.post(\n",
    "         \"http://%s/%s/predict\" % (clipper_addr, 'squeezenet-classifier-2'),\n",
    "         headers={\"Content-type\": \"application/json\"},\n",
    "         data=req_json)\n",
    "    print(response.json())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example Application - Custom Docker Containers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this final example, we will go over how to create a custom Docker container. Custom Docker containers can be utilized when model containers need outside dependencies to install, or, as is the case with our example, if they need to be installed outside of Python.\n",
    "\n",
    "For this example, we will be using the YoloV3 Real Time Object Detection System to draw bounding boxes for some images. Unlike in our previous examples, YoloV3 does not have a Python API, and must instead be downloaded and compiled using Make. To download the C files, we need to clone the darknet repo - in this case, we will be cloning a special fork made for this project that will give us the bounding box coordinates along with drawing them - and then compile it using Make. In addition, since we are no longer dealing with a Python API, but rather with a C executable, we will see that our predict function will be different.\n",
    "\n",
    "To build our custom Docker Container, we need to create a dockerfile. This dockerfile is called `PyDarknetDockerfile` and is included in the repo. For your convenience, we include the whole code here:\n",
    "```dockerfile\n",
    "FROM clipper/python36-closure-container:0.3\n",
    "\n",
    "# Install Git\n",
    "RUN apt-get update \\\n",
    "    && apt-get install -y git\n",
    "\n",
    "# Install cURL\n",
    "RUN apt-get install -y curl\n",
    "\n",
    "# Clone Darknet Repo\n",
    "RUN git clone https://github.com/RehanSD/darknet.git\n",
    "\n",
    "# Make Darknet Project\n",
    "RUN cd darknet\n",
    "RUN make -C darknet/\n",
    "\n",
    "#Download Weights\n",
    "RUN curl -o darknet/yolov3.weights https://pjreddie.com/media/files/yolov3.weights\n",
    "```\n",
    "\n",
    "In the following sections, we will break down each part of the file."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first line of the file:\n",
    "``` dockerfile\n",
    "FROM clipper/python36-closure-container:0.3\n",
    "\n",
    "LABEL maintainer=\"Dan Crankshaw <dscrankshaw@gmail.com>\"\n",
    "\n",
    "```\n",
    "are required to build the container - they specify a parent container and will flesh out the basic requirements Clipper needs to be able to use the Dockerfile. The second line just lists the author/maintainer.\n",
    "\n",
    "The next couple of lines:\n",
    "```dockerfile\n",
    "# Install Git\n",
    "RUN apt-get update \\\n",
    "    && apt-get install -y git\n",
    "\n",
    "# Install cURL\n",
    "RUN apt-get install -y curl\n",
    "```\n",
    "install the basic dependencies we need in the container - git to clone the repo, annd curl to download the pretrained yolo model weights.\n",
    "\n",
    "The last few lines:\n",
    "```dockerfile\n",
    "# Clone Darknet Repo\n",
    "RUN git clone https://github.com/RehanSD/darknet.git\n",
    "\n",
    "# Make Darknet Project\n",
    "RUN cd darknet\n",
    "RUN make -C darknet/\n",
    "\n",
    "#Download Weights\n",
    "RUN curl -o darknet/yolov3.weights https://pjreddie.com/media/files/yolov3.weights\n",
    "```\n",
    "clone the darknet repo, make it, and then download the pretrained model weights.\n",
    "\n",
    "After writing this dockerfile, all we have to do is build the image like so:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sending build context to Docker daemon  28.69MB\n",
      "Step 1/9 : FROM clipper/python36-closure-container:0.3\n",
      "0.3: Pulling from clipper/python36-closure-container\n",
      "\n",
      "\u001b[1B\n",
      "\u001b[1B\n",
      "\u001b[1B\n",
      "\u001b[1B\n",
      "\u001b[1B\n",
      "\u001b[1B\n",
      "\u001b[1B\n",
      "\u001b[1B\n",
      "\u001b[1B\n",
      "\u001b[1B\n",
      "\u001b[1B\n",
      "\u001b[1B\n",
      "\u001b[1BDigest: sha256:b164712ed0b2eb8be1db06423f35f82e563d97fc58fa770d9da2a2a8da90f904\n",
      "Status: Downloaded newer image for clipper/python36-closure-container:0.3\n",
      " ---> 74ba26b9a6ba\n",
      "Step 2/9 : RUN apt-get update     && apt-get install -y git\n",
      " ---> Running in 0ec991be662e\n",
      "Get:1 http://security.debian.org/debian-security stretch/updates InRelease [94.3 kB]\n",
      "Ign:2 http://deb.debian.org/debian stretch InRelease\n",
      "Get:3 http://deb.debian.org/debian stretch-updates InRelease [91.0 kB]\n",
      "Get:4 http://deb.debian.org/debian stretch Release [118 kB]\n",
      "Get:5 http://deb.debian.org/debian stretch Release.gpg [2434 B]\n",
      "Get:6 http://security.debian.org/debian-security stretch/updates/main amd64 Packages [513 kB]\n",
      "Get:7 http://deb.debian.org/debian stretch-updates/main amd64 Packages.diff/Index [5164 B]\n",
      "Get:8 http://deb.debian.org/debian stretch/main amd64 Packages [9500 kB]\n",
      "Get:9 http://deb.debian.org/debian stretch-updates/main amd64 Packages 2018-07-20-2027.50.pdiff [1134 B]\n",
      "Get:10 http://deb.debian.org/debian stretch-updates/main amd64 Packages 2018-07-31-2010.17.pdiff [1388 B]\n",
      "Get:10 http://deb.debian.org/debian stretch-updates/main amd64 Packages 2018-07-31-2010.17.pdiff [1388 B]\n",
      "Fetched 10.3 MB in 1s (7685 kB/s)\n",
      "Reading package lists...\n",
      "Reading package lists...\n",
      "Building dependency tree...\n",
      "Reading state information...\n",
      "The following additional packages will be installed:\n",
      "  git-man krb5-locales less libbsd0 libcurl3-gnutls libedit2 liberror-perl\n",
      "  libgpm2 libgssapi-krb5-2 libidn2-0 libk5crypto3 libkeyutils1 libkrb5-3\n",
      "  libkrb5support0 libncurses5 libnghttp2-14 libpopt0 libpsl5 librtmp1\n",
      "  libssh2-1 libssl1.0.2 libunistring0 libx11-6 libx11-data libxau6 libxcb1\n",
      "  libxdmcp6 libxext6 libxmuu1 openssh-client publicsuffix rsync xauth\n",
      "Suggested packages:\n",
      "  gettext-base git-daemon-run | git-daemon-sysvinit git-doc git-el git-email\n",
      "  git-gui gitk gitweb git-arch git-cvs git-mediawiki git-svn gpm krb5-doc\n",
      "  krb5-user keychain libpam-ssh monkeysphere ssh-askpass openssh-server\n",
      "The following NEW packages will be installed:\n",
      "  git git-man krb5-locales less libbsd0 libcurl3-gnutls libedit2 liberror-perl\n",
      "  libgpm2 libgssapi-krb5-2 libidn2-0 libk5crypto3 libkeyutils1 libkrb5-3\n",
      "  libkrb5support0 libncurses5 libnghttp2-14 libpopt0 libpsl5 librtmp1\n",
      "  libssh2-1 libssl1.0.2 libunistring0 libx11-6 libx11-data libxau6 libxcb1\n",
      "  libxdmcp6 libxext6 libxmuu1 openssh-client publicsuffix rsync xauth\n",
      "0 upgraded, 34 newly installed, 0 to remove and 24 not upgraded.\n",
      "Need to get 11.7 MB of archives.\n",
      "After this operation, 50.2 MB of additional disk space will be used.\n",
      "Get:1 http://security.debian.org/debian-security stretch/updates/main amd64 libcurl3-gnutls amd64 7.52.1-5+deb9u7 [290 kB]\n",
      "Get:2 http://security.debian.org/debian-security stretch/updates/main amd64 openssh-client amd64 1:7.4p1-10+deb9u4 [778 kB]\n",
      "Get:3 http://deb.debian.org/debian stretch/main amd64 libkeyutils1 amd64 1.5.9-9 [12.4 kB]\n",
      "Get:4 http://deb.debian.org/debian stretch/main amd64 libkrb5support0 amd64 1.15-1+deb9u1 [61.9 kB]\n",
      "Get:5 http://deb.debian.org/debian stretch/main amd64 libk5crypto3 amd64 1.15-1+deb9u1 [119 kB]\n",
      "Get:6 http://deb.debian.org/debian stretch/main amd64 libkrb5-3 amd64 1.15-1+deb9u1 [311 kB]\n",
      "Get:7 http://deb.debian.org/debian stretch/main amd64 libgssapi-krb5-2 amd64 1.15-1+deb9u1 [155 kB]\n",
      "Get:8 http://deb.debian.org/debian stretch/main amd64 libunistring0 amd64 0.9.6+really0.9.3-0.1 [279 kB]\n",
      "Get:9 http://deb.debian.org/debian stretch/main amd64 libidn2-0 amd64 0.16-1+deb9u1 [60.7 kB]\n",
      "Get:10 http://deb.debian.org/debian stretch/main amd64 libnghttp2-14 amd64 1.18.1-1 [79.1 kB]\n",
      "Get:11 http://deb.debian.org/debian stretch/main amd64 libpsl5 amd64 0.17.0-3 [41.8 kB]\n",
      "Get:12 http://deb.debian.org/debian stretch/main amd64 librtmp1 amd64 2.4+20151223.gitfa8646d.1-1+b1 [60.4 kB]\n",
      "Get:13 http://deb.debian.org/debian stretch/main amd64 libssh2-1 amd64 1.7.0-1 [138 kB]\n",
      "Get:14 http://deb.debian.org/debian stretch/main amd64 liberror-perl all 0.17024-1 [26.9 kB]\n",
      "Get:15 http://deb.debian.org/debian stretch/main amd64 git-man all 1:2.11.0-3+deb9u3 [1433 kB]\n",
      "Get:16 http://deb.debian.org/debian stretch/main amd64 git amd64 1:2.11.0-3+deb9u3 [4163 kB]\n",
      "Get:17 http://deb.debian.org/debian stretch/main amd64 libxau6 amd64 1:1.0.8-1 [20.7 kB]\n",
      "Get:18 http://deb.debian.org/debian stretch/main amd64 libpopt0 amd64 1.16-10+b2 [49.4 kB]\n",
      "Get:19 http://deb.debian.org/debian stretch/main amd64 libssl1.0.2 amd64 1.0.2l-2+deb9u3 [1294 kB]\n",
      "Get:20 http://deb.debian.org/debian stretch/main amd64 krb5-locales all 1.15-1+deb9u1 [93.8 kB]\n",
      "Get:21 http://deb.debian.org/debian stretch/main amd64 less amd64 481-2.1 [126 kB]\n",
      "Get:22 http://deb.debian.org/debian stretch/main amd64 libbsd0 amd64 0.8.3-1 [83.0 kB]\n",
      "Get:23 http://deb.debian.org/debian stretch/main amd64 libncurses5 amd64 6.0+20161126-1+deb9u2 [93.4 kB]\n",
      "Get:24 http://deb.debian.org/debian stretch/main amd64 libedit2 amd64 3.1-20160903-3 [84.8 kB]\n",
      "Get:25 http://deb.debian.org/debian stretch/main amd64 libgpm2 amd64 1.20.4-6.2+b1 [34.2 kB]\n",
      "Get:26 http://deb.debian.org/debian stretch/main amd64 libxdmcp6 amd64 1:1.1.2-3 [26.3 kB]\n",
      "Get:27 http://deb.debian.org/debian stretch/main amd64 libxcb1 amd64 1.12-1 [133 kB]\n",
      "Get:28 http://deb.debian.org/debian stretch/main amd64 libx11-data all 2:1.6.4-3 [290 kB]\n",
      "Get:29 http://deb.debian.org/debian stretch/main amd64 libx11-6 amd64 2:1.6.4-3 [747 kB]\n",
      "Get:30 http://deb.debian.org/debian stretch/main amd64 libxext6 amd64 2:1.3.3-1+b2 [52.5 kB]\n",
      "Get:31 http://deb.debian.org/debian stretch/main amd64 libxmuu1 amd64 2:1.1.2-2 [23.5 kB]\n",
      "Get:32 http://deb.debian.org/debian stretch/main amd64 rsync amd64 3.1.2-1+deb9u1 [393 kB]\n",
      "Get:33 http://deb.debian.org/debian stretch/main amd64 xauth amd64 1:1.0.9-1+b2 [39.6 kB]\n",
      "Get:34 http://deb.debian.org/debian stretch/main amd64 publicsuffix all 20180218.2049-0+deb9u1 [103 kB]\n",
      "\u001b[91mdebconf: delaying package configuration, since apt-utils is not installed\n",
      "\u001b[0mFetched 11.7 MB in 0s (22.0 MB/s)\n",
      "Selecting previously unselected package libkeyutils1:amd64.\n",
      "(Reading database ... 14696 files and directories currently installed.)\n",
      "Preparing to unpack .../00-libkeyutils1_1.5.9-9_amd64.deb ...\n",
      "Unpacking libkeyutils1:amd64 (1.5.9-9) ...\n",
      "Selecting previously unselected package libkrb5support0:amd64.\n",
      "Preparing to unpack .../01-libkrb5support0_1.15-1+deb9u1_amd64.deb ...\n",
      "Unpacking libkrb5support0:amd64 (1.15-1+deb9u1) ...\n",
      "Selecting previously unselected package libk5crypto3:amd64.\n",
      "Preparing to unpack .../02-libk5crypto3_1.15-1+deb9u1_amd64.deb ...\n",
      "Unpacking libk5crypto3:amd64 (1.15-1+deb9u1) ...\n",
      "Selecting previously unselected package libkrb5-3:amd64.\n",
      "Preparing to unpack .../03-libkrb5-3_1.15-1+deb9u1_amd64.deb ...\n",
      "Unpacking libkrb5-3:amd64 (1.15-1+deb9u1) ...\n",
      "Selecting previously unselected package libgssapi-krb5-2:amd64.\n",
      "Preparing to unpack .../04-libgssapi-krb5-2_1.15-1+deb9u1_amd64.deb ...\n",
      "Unpacking libgssapi-krb5-2:amd64 (1.15-1+deb9u1) ...\n",
      "Selecting previously unselected package libunistring0:amd64.\n",
      "Preparing to unpack .../05-libunistring0_0.9.6+really0.9.3-0.1_amd64.deb ...\n",
      "Unpacking libunistring0:amd64 (0.9.6+really0.9.3-0.1) ...\n",
      "Selecting previously unselected package libidn2-0:amd64.\n",
      "Preparing to unpack .../06-libidn2-0_0.16-1+deb9u1_amd64.deb ...\n",
      "Unpacking libidn2-0:amd64 (0.16-1+deb9u1) ...\n",
      "Selecting previously unselected package libnghttp2-14:amd64.\n",
      "Preparing to unpack .../07-libnghttp2-14_1.18.1-1_amd64.deb ...\n",
      "Unpacking libnghttp2-14:amd64 (1.18.1-1) ...\n",
      "Selecting previously unselected package libpsl5:amd64.\n",
      "Preparing to unpack .../08-libpsl5_0.17.0-3_amd64.deb ...\n",
      "Unpacking libpsl5:amd64 (0.17.0-3) ...\n",
      "Selecting previously unselected package librtmp1:amd64.\n",
      "Preparing to unpack .../09-librtmp1_2.4+20151223.gitfa8646d.1-1+b1_amd64.deb ...\n",
      "Unpacking librtmp1:amd64 (2.4+20151223.gitfa8646d.1-1+b1) ...\n",
      "Selecting previously unselected package libssh2-1:amd64.\n",
      "Preparing to unpack .../10-libssh2-1_1.7.0-1_amd64.deb ...\n",
      "Unpacking libssh2-1:amd64 (1.7.0-1) ...\n",
      "Selecting previously unselected package libcurl3-gnutls:amd64.\n",
      "Preparing to unpack .../11-libcurl3-gnutls_7.52.1-5+deb9u7_amd64.deb ...\n",
      "Unpacking libcurl3-gnutls:amd64 (7.52.1-5+deb9u7) ...\n",
      "Selecting previously unselected package liberror-perl.\n",
      "Preparing to unpack .../12-liberror-perl_0.17024-1_all.deb ...\n",
      "Unpacking liberror-perl (0.17024-1) ...\n",
      "Selecting previously unselected package git-man.\n",
      "Preparing to unpack .../13-git-man_1%3a2.11.0-3+deb9u3_all.deb ...\n",
      "Unpacking git-man (1:2.11.0-3+deb9u3) ...\n",
      "Selecting previously unselected package git.\n",
      "Preparing to unpack .../14-git_1%3a2.11.0-3+deb9u3_amd64.deb ...\n",
      "Unpacking git (1:2.11.0-3+deb9u3) ...\n",
      "Selecting previously unselected package libxau6:amd64.\n",
      "Preparing to unpack .../15-libxau6_1%3a1.0.8-1_amd64.deb ...\n",
      "Unpacking libxau6:amd64 (1:1.0.8-1) ...\n",
      "Selecting previously unselected package libpopt0:amd64.\n",
      "Preparing to unpack .../16-libpopt0_1.16-10+b2_amd64.deb ...\n",
      "Unpacking libpopt0:amd64 (1.16-10+b2) ...\n",
      "Selecting previously unselected package libssl1.0.2:amd64.\n",
      "Preparing to unpack .../17-libssl1.0.2_1.0.2l-2+deb9u3_amd64.deb ...\n",
      "Unpacking libssl1.0.2:amd64 (1.0.2l-2+deb9u3) ...\n",
      "Selecting previously unselected package krb5-locales.\n",
      "Preparing to unpack .../18-krb5-locales_1.15-1+deb9u1_all.deb ...\n",
      "Unpacking krb5-locales (1.15-1+deb9u1) ...\n",
      "Selecting previously unselected package less.\n",
      "Preparing to unpack .../19-less_481-2.1_amd64.deb ...\n",
      "Unpacking less (481-2.1) ...\n",
      "Selecting previously unselected package libbsd0:amd64.\n",
      "Preparing to unpack .../20-libbsd0_0.8.3-1_amd64.deb ...\n",
      "Unpacking libbsd0:amd64 (0.8.3-1) ...\n",
      "Selecting previously unselected package libncurses5:amd64.\n",
      "Preparing to unpack .../21-libncurses5_6.0+20161126-1+deb9u2_amd64.deb ...\n",
      "Unpacking libncurses5:amd64 (6.0+20161126-1+deb9u2) ...\n",
      "Selecting previously unselected package libedit2:amd64.\n",
      "Preparing to unpack .../22-libedit2_3.1-20160903-3_amd64.deb ...\n",
      "Unpacking libedit2:amd64 (3.1-20160903-3) ...\n",
      "Selecting previously unselected package libgpm2:amd64.\n",
      "Preparing to unpack .../23-libgpm2_1.20.4-6.2+b1_amd64.deb ...\n",
      "Unpacking libgpm2:amd64 (1.20.4-6.2+b1) ...\n",
      "Selecting previously unselected package openssh-client.\n",
      "Preparing to unpack .../24-openssh-client_1%3a7.4p1-10+deb9u4_amd64.deb ...\n",
      "Unpacking openssh-client (1:7.4p1-10+deb9u4) ...\n",
      "Selecting previously unselected package libxdmcp6:amd64.\n",
      "Preparing to unpack .../25-libxdmcp6_1%3a1.1.2-3_amd64.deb ...\n",
      "Unpacking libxdmcp6:amd64 (1:1.1.2-3) ...\n",
      "Selecting previously unselected package libxcb1:amd64.\n",
      "Preparing to unpack .../26-libxcb1_1.12-1_amd64.deb ...\n",
      "Unpacking libxcb1:amd64 (1.12-1) ...\n",
      "Selecting previously unselected package libx11-data.\n",
      "Preparing to unpack .../27-libx11-data_2%3a1.6.4-3_all.deb ...\n",
      "Unpacking libx11-data (2:1.6.4-3) ...\n",
      "Selecting previously unselected package libx11-6:amd64.\n",
      "Preparing to unpack .../28-libx11-6_2%3a1.6.4-3_amd64.deb ...\n",
      "Unpacking libx11-6:amd64 (2:1.6.4-3) ...\n",
      "Selecting previously unselected package libxext6:amd64.\n",
      "Preparing to unpack .../29-libxext6_2%3a1.3.3-1+b2_amd64.deb ...\n",
      "Unpacking libxext6:amd64 (2:1.3.3-1+b2) ...\n",
      "Selecting previously unselected package libxmuu1:amd64.\n",
      "Preparing to unpack .../30-libxmuu1_2%3a1.1.2-2_amd64.deb ...\n",
      "Unpacking libxmuu1:amd64 (2:1.1.2-2) ...\n",
      "Selecting previously unselected package rsync.\n",
      "Preparing to unpack .../31-rsync_3.1.2-1+deb9u1_amd64.deb ...\n",
      "Unpacking rsync (3.1.2-1+deb9u1) ...\n",
      "Selecting previously unselected package xauth.\n",
      "Preparing to unpack .../32-xauth_1%3a1.0.9-1+b2_amd64.deb ...\n",
      "Unpacking xauth (1:1.0.9-1+b2) ...\n",
      "Selecting previously unselected package publicsuffix.\n",
      "Preparing to unpack .../33-publicsuffix_20180218.2049-0+deb9u1_all.deb ...\n",
      "Unpacking publicsuffix (20180218.2049-0+deb9u1) ...\n",
      "Setting up libncurses5:amd64 (6.0+20161126-1+deb9u2) ...\n",
      "Setting up git-man (1:2.11.0-3+deb9u3) ...\n",
      "Setting up libpopt0:amd64 (1.16-10+b2) ...\n",
      "Setting up less (481-2.1) ...\n",
      "debconf: unable to initialize frontend: Dialog\n",
      "debconf: (TERM is not set, so the dialog frontend is not usable.)\n",
      "debconf: falling back to frontend: Readline\n",
      "Setting up libnghttp2-14:amd64 (1.18.1-1) ...\n",
      "Setting up liberror-perl (0.17024-1) ...\n",
      "Setting up libgpm2:amd64 (1.20.4-6.2+b1) ...\n",
      "Setting up librtmp1:amd64 (2.4+20151223.gitfa8646d.1-1+b1) ...\n",
      "Setting up libbsd0:amd64 (0.8.3-1) ...\n",
      "Setting up rsync (3.1.2-1+deb9u1) ...\n",
      "invoke-rc.d: could not determine current runlevel\n",
      "invoke-rc.d: policy-rc.d denied execution of restart.\n",
      "Setting up libssl1.0.2:amd64 (1.0.2l-2+deb9u3) ...\n",
      "debconf: unable to initialize frontend: Dialog\n",
      "debconf: (TERM is not set, so the dialog frontend is not usable.)\n",
      "debconf: falling back to frontend: Readline\n",
      "Setting up libssh2-1:amd64 (1.7.0-1) ...\n",
      "Setting up krb5-locales (1.15-1+deb9u1) ...\n",
      "Processing triggers for libc-bin (2.24-11+deb9u3) ...\n",
      "Setting up publicsuffix (20180218.2049-0+deb9u1) ...\n",
      "Setting up libunistring0:amd64 (0.9.6+really0.9.3-0.1) ...\n",
      "Setting up libxdmcp6:amd64 (1:1.1.2-3) ...\n",
      "Setting up libkeyutils1:amd64 (1.5.9-9) ...\n",
      "Setting up libx11-data (2:1.6.4-3) ...\n",
      "Setting up libxau6:amd64 (1:1.0.8-1) ...\n",
      "Setting up libedit2:amd64 (3.1-20160903-3) ...\n",
      "Setting up libidn2-0:amd64 (0.16-1+deb9u1) ...\n",
      "Setting up libpsl5:amd64 (0.17.0-3) ...\n",
      "Setting up libkrb5support0:amd64 (1.15-1+deb9u1) ...\n",
      "Setting up libxcb1:amd64 (1.12-1) ...\n",
      "Setting up libk5crypto3:amd64 (1.15-1+deb9u1) ...\n",
      "Setting up libx11-6:amd64 (2:1.6.4-3) ...\n",
      "Setting up libxmuu1:amd64 (2:1.1.2-2) ...\n",
      "Setting up libkrb5-3:amd64 (1.15-1+deb9u1) ...\n",
      "Setting up libxext6:amd64 (2:1.3.3-1+b2) ...\n",
      "Setting up libgssapi-krb5-2:amd64 (1.15-1+deb9u1) ...\n",
      "Setting up xauth (1:1.0.9-1+b2) ...\n",
      "Setting up openssh-client (1:7.4p1-10+deb9u4) ...\n",
      "Setting up libcurl3-gnutls:amd64 (7.52.1-5+deb9u7) ...\n",
      "Setting up git (1:2.11.0-3+deb9u3) ...\n",
      "Processing triggers for libc-bin (2.24-11+deb9u3) ...\n",
      "Removing intermediate container 0ec991be662e\n",
      " ---> efdaf995c2b0\n",
      "Step 3/9 : RUN apt-get install -y curl\n",
      " ---> Running in 5a615c872f61\n",
      "Reading package lists...\n",
      "Building dependency tree...\n",
      "Reading state information...\n",
      "The following additional packages will be installed:\n",
      "  libcurl3\n",
      "The following NEW packages will be installed:\n",
      "  curl libcurl3\n",
      "0 upgraded, 2 newly installed, 0 to remove and 24 not upgraded.\n",
      "Need to get 519 kB of archives.\n",
      "After this operation, 989 kB of additional disk space will be used.\n",
      "Get:1 http://security.debian.org/debian-security stretch/updates/main amd64 libcurl3 amd64 7.52.1-5+deb9u7 [292 kB]\n",
      "Get:2 http://security.debian.org/debian-security stretch/updates/main amd64 curl amd64 7.52.1-5+deb9u7 [228 kB]\n",
      "\u001b[91mdebconf: delaying package configuration, since apt-utils is not installed\n",
      "\u001b[0mFetched 519 kB in 0s (1595 kB/s)\n",
      "Selecting previously unselected package libcurl3:amd64.\n",
      "(Reading database ... 16191 files and directories currently installed.)\n",
      "Preparing to unpack .../libcurl3_7.52.1-5+deb9u7_amd64.deb ...\n",
      "Unpacking libcurl3:amd64 (7.52.1-5+deb9u7) ...\n",
      "Selecting previously unselected package curl.\n",
      "Preparing to unpack .../curl_7.52.1-5+deb9u7_amd64.deb ...\n",
      "Unpacking curl (7.52.1-5+deb9u7) ...\n",
      "Setting up libcurl3:amd64 (7.52.1-5+deb9u7) ...\n",
      "Processing triggers for libc-bin (2.24-11+deb9u3) ...\n",
      "Setting up curl (7.52.1-5+deb9u7) ...\n",
      "Removing intermediate container 5a615c872f61\n",
      " ---> 0ad812f99bfa\n",
      "Step 4/9 : RUN git clone https://github.com/RehanSD/darknet.git\n",
      " ---> Running in 59dce176af0d\n",
      "\u001b[91mCloning into 'darknet'...\n",
      "\u001b[0mRemoving intermediate container 59dce176af0d\n",
      " ---> a8d467d5a26b\n",
      "Step 5/9 : RUN cd darknet\n",
      " ---> Running in 0acba6af538b\n",
      "Removing intermediate container 0acba6af538b\n",
      " ---> 67f0029f6f1b\n",
      "Step 6/9 : RUN make -C darknet/\n",
      " ---> Running in 27812745273b\n",
      "make: Entering directory '/container/darknet'\n",
      "mkdir -p obj\n",
      "mkdir -p backup\n",
      "mkdir -p results\n",
      "gcc -Iinclude/ -Isrc/ -Wall -Wno-unused-result -Wno-unknown-pragmas -Wfatal-errors -fPIC -Ofast -c ./src/gemm.c -o obj/gemm.o\n",
      "gcc -Iinclude/ -Isrc/ -Wall -Wno-unused-result -Wno-unknown-pragmas -Wfatal-errors -fPIC -Ofast -c ./src/utils.c -o obj/utils.o\n",
      "gcc -Iinclude/ -Isrc/ -Wall -Wno-unused-result -Wno-unknown-pragmas -Wfatal-errors -fPIC -Ofast -c ./src/cuda.c -o obj/cuda.o\n",
      "gcc -Iinclude/ -Isrc/ -Wall -Wno-unused-result -Wno-unknown-pragmas -Wfatal-errors -fPIC -Ofast -c ./src/deconvolutional_layer.c -o obj/deconvolutional_layer.o\n",
      "gcc -Iinclude/ -Isrc/ -Wall -Wno-unused-result -Wno-unknown-pragmas -Wfatal-errors -fPIC -Ofast -c ./src/convolutional_layer.c -o obj/convolutional_layer.o\n",
      "gcc -Iinclude/ -Isrc/ -Wall -Wno-unused-result -Wno-unknown-pragmas -Wfatal-errors -fPIC -Ofast -c ./src/list.c -o obj/list.o\n",
      "gcc -Iinclude/ -Isrc/ -Wall -Wno-unused-result -Wno-unknown-pragmas -Wfatal-errors -fPIC -Ofast -c ./src/image.c -o obj/image.o\n",
      "gcc -Iinclude/ -Isrc/ -Wall -Wno-unused-result -Wno-unknown-pragmas -Wfatal-errors -fPIC -Ofast -c ./src/activations.c -o obj/activations.o\n",
      "gcc -Iinclude/ -Isrc/ -Wall -Wno-unused-result -Wno-unknown-pragmas -Wfatal-errors -fPIC -Ofast -c ./src/im2col.c -o obj/im2col.o\n",
      "gcc -Iinclude/ -Isrc/ -Wall -Wno-unused-result -Wno-unknown-pragmas -Wfatal-errors -fPIC -Ofast -c ./src/col2im.c -o obj/col2im.o\n",
      "gcc -Iinclude/ -Isrc/ -Wall -Wno-unused-result -Wno-unknown-pragmas -Wfatal-errors -fPIC -Ofast -c ./src/blas.c -o obj/blas.o\n",
      "gcc -Iinclude/ -Isrc/ -Wall -Wno-unused-result -Wno-unknown-pragmas -Wfatal-errors -fPIC -Ofast -c ./src/crop_layer.c -o obj/crop_layer.o\n",
      "gcc -Iinclude/ -Isrc/ -Wall -Wno-unused-result -Wno-unknown-pragmas -Wfatal-errors -fPIC -Ofast -c ./src/dropout_layer.c -o obj/dropout_layer.o\n",
      "gcc -Iinclude/ -Isrc/ -Wall -Wno-unused-result -Wno-unknown-pragmas -Wfatal-errors -fPIC -Ofast -c ./src/maxpool_layer.c -o obj/maxpool_layer.o\n",
      "gcc -Iinclude/ -Isrc/ -Wall -Wno-unused-result -Wno-unknown-pragmas -Wfatal-errors -fPIC -Ofast -c ./src/softmax_layer.c -o obj/softmax_layer.o\n",
      "gcc -Iinclude/ -Isrc/ -Wall -Wno-unused-result -Wno-unknown-pragmas -Wfatal-errors -fPIC -Ofast -c ./src/data.c -o obj/data.o\n",
      "gcc -Iinclude/ -Isrc/ -Wall -Wno-unused-result -Wno-unknown-pragmas -Wfatal-errors -fPIC -Ofast -c ./src/matrix.c -o obj/matrix.o\n",
      "gcc -Iinclude/ -Isrc/ -Wall -Wno-unused-result -Wno-unknown-pragmas -Wfatal-errors -fPIC -Ofast -c ./src/network.c -o obj/network.o\n",
      "gcc -Iinclude/ -Isrc/ -Wall -Wno-unused-result -Wno-unknown-pragmas -Wfatal-errors -fPIC -Ofast -c ./src/connected_layer.c -o obj/connected_layer.o\n",
      "gcc -Iinclude/ -Isrc/ -Wall -Wno-unused-result -Wno-unknown-pragmas -Wfatal-errors -fPIC -Ofast -c ./src/cost_layer.c -o obj/cost_layer.o\n",
      "gcc -Iinclude/ -Isrc/ -Wall -Wno-unused-result -Wno-unknown-pragmas -Wfatal-errors -fPIC -Ofast -c ./src/parser.c -o obj/parser.o\n",
      "gcc -Iinclude/ -Isrc/ -Wall -Wno-unused-result -Wno-unknown-pragmas -Wfatal-errors -fPIC -Ofast -c ./src/option_list.c -o obj/option_list.o\n",
      "gcc -Iinclude/ -Isrc/ -Wall -Wno-unused-result -Wno-unknown-pragmas -Wfatal-errors -fPIC -Ofast -c ./src/detection_layer.c -o obj/detection_layer.o\n",
      "gcc -Iinclude/ -Isrc/ -Wall -Wno-unused-result -Wno-unknown-pragmas -Wfatal-errors -fPIC -Ofast -c ./src/route_layer.c -o obj/route_layer.o\n",
      "gcc -Iinclude/ -Isrc/ -Wall -Wno-unused-result -Wno-unknown-pragmas -Wfatal-errors -fPIC -Ofast -c ./src/upsample_layer.c -o obj/upsample_layer.o\n",
      "gcc -Iinclude/ -Isrc/ -Wall -Wno-unused-result -Wno-unknown-pragmas -Wfatal-errors -fPIC -Ofast -c ./src/box.c -o obj/box.o\n",
      "gcc -Iinclude/ -Isrc/ -Wall -Wno-unused-result -Wno-unknown-pragmas -Wfatal-errors -fPIC -Ofast -c ./src/normalization_layer.c -o obj/normalization_layer.o\n",
      "gcc -Iinclude/ -Isrc/ -Wall -Wno-unused-result -Wno-unknown-pragmas -Wfatal-errors -fPIC -Ofast -c ./src/avgpool_layer.c -o obj/avgpool_layer.o\n",
      "gcc -Iinclude/ -Isrc/ -Wall -Wno-unused-result -Wno-unknown-pragmas -Wfatal-errors -fPIC -Ofast -c ./src/layer.c -o obj/layer.o\n",
      "gcc -Iinclude/ -Isrc/ -Wall -Wno-unused-result -Wno-unknown-pragmas -Wfatal-errors -fPIC -Ofast -c ./src/local_layer.c -o obj/local_layer.o\n",
      "gcc -Iinclude/ -Isrc/ -Wall -Wno-unused-result -Wno-unknown-pragmas -Wfatal-errors -fPIC -Ofast -c ./src/shortcut_layer.c -o obj/shortcut_layer.o\n",
      "gcc -Iinclude/ -Isrc/ -Wall -Wno-unused-result -Wno-unknown-pragmas -Wfatal-errors -fPIC -Ofast -c ./src/logistic_layer.c -o obj/logistic_layer.o\n",
      "gcc -Iinclude/ -Isrc/ -Wall -Wno-unused-result -Wno-unknown-pragmas -Wfatal-errors -fPIC -Ofast -c ./src/activation_layer.c -o obj/activation_layer.o\n",
      "gcc -Iinclude/ -Isrc/ -Wall -Wno-unused-result -Wno-unknown-pragmas -Wfatal-errors -fPIC -Ofast -c ./src/rnn_layer.c -o obj/rnn_layer.o\n",
      "gcc -Iinclude/ -Isrc/ -Wall -Wno-unused-result -Wno-unknown-pragmas -Wfatal-errors -fPIC -Ofast -c ./src/gru_layer.c -o obj/gru_layer.o\n",
      "gcc -Iinclude/ -Isrc/ -Wall -Wno-unused-result -Wno-unknown-pragmas -Wfatal-errors -fPIC -Ofast -c ./src/crnn_layer.c -o obj/crnn_layer.o\n",
      "gcc -Iinclude/ -Isrc/ -Wall -Wno-unused-result -Wno-unknown-pragmas -Wfatal-errors -fPIC -Ofast -c ./src/demo.c -o obj/demo.o\n",
      "gcc -Iinclude/ -Isrc/ -Wall -Wno-unused-result -Wno-unknown-pragmas -Wfatal-errors -fPIC -Ofast -c ./src/batchnorm_layer.c -o obj/batchnorm_layer.o\n",
      "gcc -Iinclude/ -Isrc/ -Wall -Wno-unused-result -Wno-unknown-pragmas -Wfatal-errors -fPIC -Ofast -c ./src/region_layer.c -o obj/region_layer.o\n",
      "gcc -Iinclude/ -Isrc/ -Wall -Wno-unused-result -Wno-unknown-pragmas -Wfatal-errors -fPIC -Ofast -c ./src/reorg_layer.c -o obj/reorg_layer.o\n",
      "gcc -Iinclude/ -Isrc/ -Wall -Wno-unused-result -Wno-unknown-pragmas -Wfatal-errors -fPIC -Ofast -c ./src/tree.c -o obj/tree.o\n",
      "gcc -Iinclude/ -Isrc/ -Wall -Wno-unused-result -Wno-unknown-pragmas -Wfatal-errors -fPIC -Ofast -c ./src/lstm_layer.c -o obj/lstm_layer.o\n",
      "gcc -Iinclude/ -Isrc/ -Wall -Wno-unused-result -Wno-unknown-pragmas -Wfatal-errors -fPIC -Ofast -c ./src/l2norm_layer.c -o obj/l2norm_layer.o\n",
      "gcc -Iinclude/ -Isrc/ -Wall -Wno-unused-result -Wno-unknown-pragmas -Wfatal-errors -fPIC -Ofast -c ./src/yolo_layer.c -o obj/yolo_layer.o\n",
      "gcc -Iinclude/ -Isrc/ -Wall -Wno-unused-result -Wno-unknown-pragmas -Wfatal-errors -fPIC -Ofast -c ./src/iseg_layer.c -o obj/iseg_layer.o\n",
      "gcc -Wall -Wno-unused-result -Wno-unknown-pragmas -Wfatal-errors -fPIC -Ofast -shared obj/gemm.o obj/utils.o obj/cuda.o obj/deconvolutional_layer.o obj/convolutional_layer.o obj/list.o obj/image.o obj/activations.o obj/im2col.o obj/col2im.o obj/blas.o obj/crop_layer.o obj/dropout_layer.o obj/maxpool_layer.o obj/softmax_layer.o obj/data.o obj/matrix.o obj/network.o obj/connected_layer.o obj/cost_layer.o obj/parser.o obj/option_list.o obj/detection_layer.o obj/route_layer.o obj/upsample_layer.o obj/box.o obj/normalization_layer.o obj/avgpool_layer.o obj/layer.o obj/local_layer.o obj/shortcut_layer.o obj/logistic_layer.o obj/activation_layer.o obj/rnn_layer.o obj/gru_layer.o obj/crnn_layer.o obj/demo.o obj/batchnorm_layer.o obj/region_layer.o obj/reorg_layer.o obj/tree.o obj/lstm_layer.o obj/l2norm_layer.o obj/yolo_layer.o obj/iseg_layer.o -o libdarknet.so -lm -pthread \n",
      "ar rcs libdarknet.a obj/gemm.o obj/utils.o obj/cuda.o obj/deconvolutional_layer.o obj/convolutional_layer.o obj/list.o obj/image.o obj/activations.o obj/im2col.o obj/col2im.o obj/blas.o obj/crop_layer.o obj/dropout_layer.o obj/maxpool_layer.o obj/softmax_layer.o obj/data.o obj/matrix.o obj/network.o obj/connected_layer.o obj/cost_layer.o obj/parser.o obj/option_list.o obj/detection_layer.o obj/route_layer.o obj/upsample_layer.o obj/box.o obj/normalization_layer.o obj/avgpool_layer.o obj/layer.o obj/local_layer.o obj/shortcut_layer.o obj/logistic_layer.o obj/activation_layer.o obj/rnn_layer.o obj/gru_layer.o obj/crnn_layer.o obj/demo.o obj/batchnorm_layer.o obj/region_layer.o obj/reorg_layer.o obj/tree.o obj/lstm_layer.o obj/l2norm_layer.o obj/yolo_layer.o obj/iseg_layer.o\n",
      "gcc -Iinclude/ -Isrc/ -Wall -Wno-unused-result -Wno-unknown-pragmas -Wfatal-errors -fPIC -Ofast -c ./examples/captcha.c -o obj/captcha.o\n",
      "gcc -Iinclude/ -Isrc/ -Wall -Wno-unused-result -Wno-unknown-pragmas -Wfatal-errors -fPIC -Ofast -c ./examples/lsd.c -o obj/lsd.o\n",
      "gcc -Iinclude/ -Isrc/ -Wall -Wno-unused-result -Wno-unknown-pragmas -Wfatal-errors -fPIC -Ofast -c ./examples/super.c -o obj/super.o\n",
      "gcc -Iinclude/ -Isrc/ -Wall -Wno-unused-result -Wno-unknown-pragmas -Wfatal-errors -fPIC -Ofast -c ./examples/art.c -o obj/art.o\n",
      "gcc -Iinclude/ -Isrc/ -Wall -Wno-unused-result -Wno-unknown-pragmas -Wfatal-errors -fPIC -Ofast -c ./examples/tag.c -o obj/tag.o\n",
      "gcc -Iinclude/ -Isrc/ -Wall -Wno-unused-result -Wno-unknown-pragmas -Wfatal-errors -fPIC -Ofast -c ./examples/cifar.c -o obj/cifar.o\n",
      "gcc -Iinclude/ -Isrc/ -Wall -Wno-unused-result -Wno-unknown-pragmas -Wfatal-errors -fPIC -Ofast -c ./examples/go.c -o obj/go.o\n",
      "gcc -Iinclude/ -Isrc/ -Wall -Wno-unused-result -Wno-unknown-pragmas -Wfatal-errors -fPIC -Ofast -c ./examples/rnn.c -o obj/rnn.o\n",
      "gcc -Iinclude/ -Isrc/ -Wall -Wno-unused-result -Wno-unknown-pragmas -Wfatal-errors -fPIC -Ofast -c ./examples/segmenter.c -o obj/segmenter.o\n",
      "gcc -Iinclude/ -Isrc/ -Wall -Wno-unused-result -Wno-unknown-pragmas -Wfatal-errors -fPIC -Ofast -c ./examples/regressor.c -o obj/regressor.o\n",
      "gcc -Iinclude/ -Isrc/ -Wall -Wno-unused-result -Wno-unknown-pragmas -Wfatal-errors -fPIC -Ofast -c ./examples/classifier.c -o obj/classifier.o\n",
      "gcc -Iinclude/ -Isrc/ -Wall -Wno-unused-result -Wno-unknown-pragmas -Wfatal-errors -fPIC -Ofast -c ./examples/coco.c -o obj/coco.o\n",
      "gcc -Iinclude/ -Isrc/ -Wall -Wno-unused-result -Wno-unknown-pragmas -Wfatal-errors -fPIC -Ofast -c ./examples/yolo.c -o obj/yolo.o\n",
      "gcc -Iinclude/ -Isrc/ -Wall -Wno-unused-result -Wno-unknown-pragmas -Wfatal-errors -fPIC -Ofast -c ./examples/detector.c -o obj/detector.o\n",
      "gcc -Iinclude/ -Isrc/ -Wall -Wno-unused-result -Wno-unknown-pragmas -Wfatal-errors -fPIC -Ofast -c ./examples/nightmare.c -o obj/nightmare.o\n",
      "gcc -Iinclude/ -Isrc/ -Wall -Wno-unused-result -Wno-unknown-pragmas -Wfatal-errors -fPIC -Ofast -c ./examples/instance-segmenter.c -o obj/instance-segmenter.o\n",
      "gcc -Iinclude/ -Isrc/ -Wall -Wno-unused-result -Wno-unknown-pragmas -Wfatal-errors -fPIC -Ofast -c ./examples/darknet.c -o obj/darknet.o\n",
      "gcc -Iinclude/ -Isrc/ -Wall -Wno-unused-result -Wno-unknown-pragmas -Wfatal-errors -fPIC -Ofast obj/captcha.o obj/lsd.o obj/super.o obj/art.o obj/tag.o obj/cifar.o obj/go.o obj/rnn.o obj/segmenter.o obj/regressor.o obj/classifier.o obj/coco.o obj/yolo.o obj/detector.o obj/nightmare.o obj/instance-segmenter.o obj/darknet.o libdarknet.a -o darknet -lm -pthread  libdarknet.a\n",
      "make: Leaving directory '/container/darknet'\n",
      "Removing intermediate container 27812745273b\n",
      " ---> dab0c8027fa5\n",
      "Step 7/9 : RUN curl -o darknet/yolov3.weights https://pjreddie.com/media/files/yolov3.weights\n",
      " ---> Running in 27c6cff485f8\n",
      "\u001b[91m  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "100  236M  100  236M    0     0  90.0M      0  0:00:02  0:00:02 --:--:-- 90.0M\n",
      "\u001b[0mRemoving intermediate container 27c6cff485f8\n",
      " ---> 459c03fca442\n",
      "Step 8/9 : COPY containers/python/python_closure_container.py        containers/python/container_entry.sh /container/\n",
      "COPY failed: stat /var/lib/docker/tmp/docker-builder907375539/containers/python/python_closure_container.py: no such file or directory\n"
     ]
    }
   ],
   "source": [
    "!docker build -t clipper/darknet-yolov3-container -f PyDarknetDockerfile ."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predict Function\n",
    "Now we build the predict function. We must first deserialize the image that we serialized in our request - similar to how we did in the PyTorch example, and then write it to a file to run darknet on it. Since darknet is a C executable, we must call it using the subprocess API. It is not strictly neccessary to print out the output of calling darknet, but it is useful to have the output for the sake of debugging."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import subprocess\n",
    "import base64\n",
    "import io\n",
    "import os\n",
    "def yolo_pred(imgs):\n",
    "    import base64\n",
    "    import io\n",
    "    import os\n",
    "    import tempfile\n",
    "    import subprocess\n",
    "#     os.chdir(\"darknet/\")\n",
    "    num_imgs = len(imgs)\n",
    "    ret_coords = []\n",
    "    predict_procs = []\n",
    "    file_names = []\n",
    "    for i in range(num_imgs):\n",
    "        # Create a temp file to write to\n",
    "        tmp = tempfile.NamedTemporaryFile('wb', delete=False, suffix='.jpg')\n",
    "        tmp.write(io.BytesIO(imgs[i]).getvalue())\n",
    "        tmp.close()\n",
    "        file_names.append(tmp.name)\n",
    "    \n",
    "    for file_name in file_names:\n",
    "        process = subprocess.Popen(\n",
    "            ['./darknet',\n",
    "             'detector',\n",
    "             'test',\n",
    "             './cfg/coco.data',\n",
    "             './cfg/yolov3.cfg',\n",
    "             './yolov3.weights',\n",
    "             file_name,\n",
    "             '-json',\n",
    "             '-dont_show',\n",
    "             '-ext_output', '>',\n",
    "             '{}.txt'.format(file_name+'_result')], stdout=subprocess.PIPE)\n",
    "        predict_procs.append(process)\n",
    "        \n",
    "    for process in predict_procs:\n",
    "        process.wait()\n",
    "    \n",
    "    for file_name in file_names:\n",
    "        for line in process.stdout:\n",
    "            print(line)\n",
    "        with open(file_name+'_result.txt', 'r') as myfile:\n",
    "            text = myfile.read()\n",
    "            ret_coords += [text]\n",
    "    return ret_coords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "18-09-07:02:59:48 INFO     [deployer_utils.py:44] Saving function to /tmp/clipper/tmpslq_mawa\n",
      "18-09-07:02:59:48 INFO     [deployer_utils.py:54] Serialized and supplied predict function\n",
      "18-09-07:02:59:48 INFO     [python.py:192] Python closure saved\n",
      "18-09-07:02:59:48 INFO     [clipper_admin.py:452] Building model Docker image with model data from /tmp/clipper/tmpslq_mawa\n",
      "18-09-07:02:59:48 INFO     [clipper_admin.py:456] {'stream': 'Step 1/2 : FROM clipper/custom-model-image:62fd73f1ca'}\n",
      "18-09-07:02:59:48 INFO     [clipper_admin.py:456] {'stream': '\\n'}\n",
      "18-09-07:02:59:48 INFO     [clipper_admin.py:456] {'stream': ' ---> 6668ccaf6e90\\n'}\n",
      "18-09-07:02:59:48 INFO     [clipper_admin.py:456] {'stream': 'Step 2/2 : COPY /tmp/clipper/tmpslq_mawa /model/'}\n",
      "18-09-07:02:59:48 INFO     [clipper_admin.py:456] {'stream': '\\n'}\n",
      "18-09-07:02:59:48 INFO     [clipper_admin.py:456] {'stream': ' ---> 442733c54b0d\\n'}\n",
      "18-09-07:02:59:48 INFO     [clipper_admin.py:456] {'aux': {'ID': 'sha256:442733c54b0d8847efa8c1dd396697a49ba50a7c61f79d81166fffbe38422a5b'}}\n",
      "18-09-07:02:59:48 INFO     [clipper_admin.py:456] {'stream': 'Successfully built 442733c54b0d\\n'}\n",
      "18-09-07:02:59:48 INFO     [clipper_admin.py:456] {'stream': 'Successfully tagged yolov3:4\\n'}\n",
      "18-09-07:02:59:48 INFO     [clipper_admin.py:458] Pushing model Docker image to yolov3:4\n",
      "18-09-07:02:59:49 INFO     [docker_container_manager.py:257] Found 0 replicas for yolov3:4. Adding 1\n",
      "18-09-07:02:59:56 ERROR    [clipper_admin.py:630] Received error status code: 400 and message: model with name 'yolov3' and version '4' already exists\n"
     ]
    },
    {
     "ename": "ClipperException",
     "evalue": "Received error status code: 400 and message: model with name 'yolov3' and version '4' already exists",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mClipperException\u001b[0m                          Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-92-17ffe65e2731>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0minput_type\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"bytes\"\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0;31m# The type of data the model function expects as input\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mfunc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0myolo_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;31m# The model function to deploy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m     \u001b[0mbase_image\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'clipper/custom-model-image:62fd73f1ca'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m )\n",
      "\u001b[0;32m~/miniconda3/lib/python3.6/site-packages/clipper_admin/deployers/python.py\u001b[0m in \u001b[0;36mdeploy_python_closure\u001b[0;34m(clipper_conn, name, version, input_type, func, base_image, labels, registry, num_replicas, batch_size, pkgs_to_install)\u001b[0m\n\u001b[1;32m    220\u001b[0m     clipper_conn.build_and_deploy_model(\n\u001b[1;32m    221\u001b[0m         \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mversion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mserialization_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbase_image\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 222\u001b[0;31m         registry, num_replicas, batch_size, pkgs_to_install)\n\u001b[0m\u001b[1;32m    223\u001b[0m     \u001b[0;31m# Remove temp files\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    224\u001b[0m     \u001b[0mshutil\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrmtree\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mserialization_dir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.6/site-packages/clipper_admin/clipper_admin.py\u001b[0m in \u001b[0;36mbuild_and_deploy_model\u001b[0;34m(self, name, version, input_type, model_data_path, base_image, labels, container_registry, num_replicas, batch_size, pkgs_to_install)\u001b[0m\n\u001b[1;32m    336\u001b[0m                                  container_registry, pkgs_to_install)\n\u001b[1;32m    337\u001b[0m         self.deploy_model(name, version, input_type, image, labels,\n\u001b[0;32m--> 338\u001b[0;31m                           num_replicas, batch_size)\n\u001b[0m\u001b[1;32m    339\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    340\u001b[0m     def build_model(self,\n",
      "\u001b[0;32m~/miniconda3/lib/python3.6/site-packages/clipper_admin/clipper_admin.py\u001b[0m in \u001b[0;36mdeploy_model\u001b[0;34m(self, name, version, input_type, image, labels, num_replicas, batch_size)\u001b[0m\n\u001b[1;32m    549\u001b[0m             \u001b[0mimage\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    550\u001b[0m             \u001b[0mlabels\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 551\u001b[0;31m             batch_size=batch_size)\n\u001b[0m\u001b[1;32m    552\u001b[0m         logger.info(\"Done deploying model {name}:{version}.\".format(\n\u001b[1;32m    553\u001b[0m             name=name, version=version))\n",
      "\u001b[0;32m~/miniconda3/lib/python3.6/site-packages/clipper_admin/clipper_admin.py\u001b[0m in \u001b[0;36mregister_model\u001b[0;34m(self, name, version, input_type, image, labels, batch_size)\u001b[0m\n\u001b[1;32m    629\u001b[0m                 code=r.status_code, msg=r.text)\n\u001b[1;32m    630\u001b[0m             \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merror\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 631\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mClipperException\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    632\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    633\u001b[0m             logger.info(\n",
      "\u001b[0;31mClipperException\u001b[0m: Received error status code: 400 and message: model with name 'yolov3' and version '4' already exists"
     ]
    }
   ],
   "source": [
    "from clipper_admin.deployers import python as python_deployer\n",
    "python_deployer.deploy_python_closure(\n",
    "    clipper_conn,\n",
    "    name=\"yolov3\",  # The name of the model in Clipper\n",
    "    version=4,  # A unique identifier to assign to this model.\n",
    "    input_type=\"bytes\",  # The type of data the model function expects as input\n",
    "    func=yolo_pred, # The model function to deploy\n",
    "    base_image='clipper/darknet-yolov3-container'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "18-09-07:03:01:07 INFO     [clipper_admin.py:201] Application darknet-app-3 was successfully registered\n"
     ]
    }
   ],
   "source": [
    "clipper_conn.register_application(\n",
    "    name=\"darknet-app\",\n",
    "    input_type=\"bytes\",\n",
    "    default_output=\"Default\",\n",
    "    slo_micros=5000000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "18-09-07:03:01:10 INFO     [clipper_admin.py:263] Model yolov3 is now linked to application darknet-app-3\n"
     ]
    }
   ],
   "source": [
    "clipper_conn.link_model_to_app(app_name=\"darknet-app\", model_name=\"yolov3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'query_id': 17, 'output': 'Default', 'default': True, 'default_explanation': 'No connected models found for query'}\n"
     ]
    }
   ],
   "source": [
    "import requests, json\n",
    "url = \"http://%s/darknet-app/predict\" % clipper_addr\n",
    "req_json = json.dumps({\n",
    "    \"input\":\n",
    "    base64.b64encode(open('images/dog.jpg', \"rb\").read()).decode() # bytes to unicode\n",
    "})\n",
    "headers = {'Content-type': 'application/json'}\n",
    "r = requests.post(url, headers=headers, data=req_json)\n",
    "print(r.json())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stopping Clipper\n",
    "If you run into issues and want to completely stop Clipper, you can do this by calling [`ClipperConnection.stop_all()`](http://docs.clipper.ai/en/latest/#clipper_admin.ClipperConnection.stop_all)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clipper_conn.stop_all()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When you list all the Docker containers a final time, you should see that all of the Clipper containers have been stopped."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!docker ps --filter label=ai.clipper.container.label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can now call `clipper_conn.start_clipper()` again without running into errors."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

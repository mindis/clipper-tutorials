{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tutorial 3: Clipper in Action with Pong"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have already explored some of the features of Clipper (insert recap here). Now let's take a look at Clipper in action with Pong! Released by Atari in 1972, Pong was the first commercially successful video game. You can read more about it <a href=\"https://en.wikipedia.org/wiki/Pong\">here</a>\n",
    "\n",
    "The goal of this tutorial is to use Clipper to deploy several AI policies to play against, and in doing so explore:\n",
    "(list of Clipper features we want to highlight)\n",
    "\n",
    "This tutorial will be broken up into 3 main parts:\n",
    "#### 1. Starting Clipper and Deploying First Policy\n",
    "#### 2. Training a Better Model\n",
    "#### 3. Deploying an updated, trained model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1: Starting Clipper and Deploying First Policy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Install packaged env from requirements.txt (not sure if we should do this before opening jupyter notebook or not)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import dependencies\n",
    "from clipper_admin import ClipperConnection, DockerContainerManager\n",
    "from clipper_admin.deployers import python as py_deployer\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from datascience import *\n",
    "from sklearn import linear_model\n",
    "from IPython.display import Image\n",
    "from IPython.core.display import HTML \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our first step is to get Clipper started and deploy our first AI policy: one that guesses which direction to move the paddle randomly. First, start Docker (or make sure it is running)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "18-09-05:22:04:23 INFO     [clipper_admin.py:1258] Stopped all Clipper cluster and all model containers\n",
      "18-09-05:22:04:23 INFO     [docker_container_manager.py:119] Starting managed Redis instance in Docker\n",
      "18-09-05:22:04:26 INFO     [clipper_admin.py:126] Clipper is running\n"
     ]
    }
   ],
   "source": [
    "#Starting Clipper, make sure you have Docker running before you run this cell\n",
    "clipper_conn = ClipperConnection(DockerContainerManager())\n",
    "clipper_conn.stop_all()\n",
    "clipper_conn.start_clipper()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Running the cell below will register an application in Clipper called \"pong\" and create a Clipper endpoint for our random policy at http://localhost:1337/pong/predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "18-09-05:22:04:58 INFO     [clipper_admin.py:201] Application pong was successfully registered\n",
      "18-09-05:22:04:58 INFO     [deployer_utils.py:44] Saving function to /tmp/clipper/tmpxesfqfdo\n",
      "18-09-05:22:04:58 INFO     [deployer_utils.py:54] Serialized and supplied predict function\n",
      "18-09-05:22:04:58 INFO     [python.py:192] Python closure saved\n",
      "18-09-05:22:04:58 INFO     [python.py:202] Using Python 3.5 base image\n",
      "18-09-05:22:04:58 INFO     [clipper_admin.py:452] Building model Docker image with model data from /tmp/clipper/tmpxesfqfdo\n",
      "18-09-05:22:04:59 INFO     [clipper_admin.py:456] {'stream': 'Step 1/2 : FROM clipper/python35-closure-container:0.3.0'}\n",
      "18-09-05:22:04:59 INFO     [clipper_admin.py:456] {'stream': '\\n'}\n",
      "18-09-05:22:04:59 INFO     [clipper_admin.py:456] {'stream': ' ---> 1fc910c1ed28\\n'}\n",
      "18-09-05:22:04:59 INFO     [clipper_admin.py:456] {'stream': 'Step 2/2 : COPY /tmp/clipper/tmpxesfqfdo /model/'}\n",
      "18-09-05:22:04:59 INFO     [clipper_admin.py:456] {'stream': '\\n'}\n",
      "18-09-05:22:04:59 INFO     [clipper_admin.py:456] {'stream': ' ---> e074c7b5723c\\n'}\n",
      "18-09-05:22:04:59 INFO     [clipper_admin.py:456] {'aux': {'ID': 'sha256:e074c7b5723c993219a629b1d197ca5f51c8f38fa33a5912cee41896e3d1dbb4'}}\n",
      "18-09-05:22:04:59 INFO     [clipper_admin.py:456] {'stream': 'Successfully built e074c7b5723c\\n'}\n",
      "18-09-05:22:04:59 INFO     [clipper_admin.py:456] {'stream': 'Successfully tagged pong:1\\n'}\n",
      "18-09-05:22:04:59 INFO     [clipper_admin.py:458] Pushing model Docker image to pong:1\n",
      "18-09-05:22:05:01 INFO     [docker_container_manager.py:257] Found 0 replicas for pong:1. Adding 1\n",
      "18-09-05:22:05:07 INFO     [clipper_admin.py:635] Successfully registered model pong:1\n",
      "18-09-05:22:05:07 INFO     [clipper_admin.py:553] Done deploying model pong:1.\n",
      "18-09-05:22:05:07 INFO     [clipper_admin.py:263] Model pong is now linked to application pong\n"
     ]
    }
   ],
   "source": [
    "def random_predict(xs):\n",
    "    action = random.randint(0, 2)\n",
    "    return [str(action) for _ in xs]\n",
    "\n",
    "py_deployer.create_endpoint(clipper_conn, name=\"pong\", input_type=\"doubles\", func=random_predict,\n",
    "                            default_output=\"0\", slo_micros=100000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have a model deployed, let's see how it works! Run the cell below to start the game"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18-09-05:22:05:14 INFO     [pong-server.py:109] Starting Pong Server on localhost:3000\n",
      "18-09-05:22:05:15 INFO     [pong-server.py:51] Local path: /Users/hari/Desktop/Cal/rise/clipper-tutorials/static/index.html\n",
      "127.0.0.1 - - [05/Sep/2018 22:05:15] \"GET /pong/ HTTP/1.1\" 200 -\n",
      "18-09-05:22:05:15 INFO     [pong-server.py:51] Local path: /Users/hari/Desktop/Cal/rise/clipper-tutorials/static/pong.css\n",
      "127.0.0.1 - - [05/Sep/2018 22:05:15] \"GET /pong/pong.css HTTP/1.1\" 200 -\n",
      "18-09-05:22:05:15 INFO     [pong-server.py:51] Local path: /Users/hari/Desktop/Cal/rise/clipper-tutorials/static/game.js\n",
      "127.0.0.1 - - [05/Sep/2018 22:05:15] \"GET /pong/game.js HTTP/1.1\" 200 -\n",
      "18-09-05:22:05:15 INFO     [pong-server.py:51] Local path: /Users/hari/Desktop/Cal/rise/clipper-tutorials/static/pong.js\n",
      "127.0.0.1 - - [05/Sep/2018 22:05:15] \"GET /pong/pong.js HTTP/1.1\" 200 -\n",
      "18-09-05:22:05:15 INFO     [pong-server.py:51] Local path: /Users/hari/Desktop/Cal/rise/clipper-tutorials/static/images/press1.png\n",
      "18-09-05:22:05:15 INFO     [pong-server.py:51] Local path: /Users/hari/Desktop/Cal/rise/clipper-tutorials/static/images/press2.png\n",
      "18-09-05:22:05:15 INFO     [pong-server.py:51] Local path: /Users/hari/Desktop/Cal/rise/clipper-tutorials/static/images/winner.png\n",
      "127.0.0.1 - - [05/Sep/2018 22:05:15] \"GET /pong/images/press1.png HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [05/Sep/2018 22:05:15] \"GET /pong/images/winner.png HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [05/Sep/2018 22:05:15] \"GET /pong/images/press2.png HTTP/1.1\" 200 -\n",
      "18-09-05:22:05:16 INFO     [pong-server.py:51] Local path: /Users/hari/Desktop/Cal/rise/clipper-tutorials/static/sounds/ping.wav\n",
      "127.0.0.1 - - [05/Sep/2018 22:05:16] \"GET /pong/sounds/ping.wav HTTP/1.1\" 200 -\n",
      "18-09-05:22:05:16 INFO     [pong-server.py:51] Local path: /Users/hari/Desktop/Cal/rise/clipper-tutorials/static/sounds/pong.wav\n",
      "18-09-05:22:05:16 INFO     [pong-server.py:51] Local path: /Users/hari/Desktop/Cal/rise/clipper-tutorials/static/sounds/wall.wav\n",
      "127.0.0.1 - - [05/Sep/2018 22:05:16] \"GET /pong/sounds/pong.wav HTTP/1.1\" 200 -\n",
      "18-09-05:22:05:16 INFO     [pong-server.py:51] Local path: /Users/hari/Desktop/Cal/rise/clipper-tutorials/static/sounds/goal.wav\n",
      "127.0.0.1 - - [05/Sep/2018 22:05:16] \"GET /pong/sounds/goal.wav HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [05/Sep/2018 22:05:16] \"GET /pong/sounds/wall.wav HTTP/1.1\" 200 -\n",
      "18-09-05:22:05:16 INFO     [pong-server.py:51] Local path: /favicon.ico\n",
      "127.0.0.1 - - [05/Sep/2018 22:05:16] code 403, message Forbidden\n",
      "127.0.0.1 - - [05/Sep/2018 22:05:16] \"GET /favicon.ico HTTP/1.1\" 403 -\n",
      "^C\n",
      "Traceback (most recent call last):\n",
      "  File \"pong-server.py\", line 117, in <module>\n",
      "    run(clipper_addr)\n",
      "  File \"pong-server.py\", line 112, in run\n",
      "    server.serve_forever()\n",
      "  File \"/Users/hari/anaconda/lib/python3.5/socketserver.py\", line 232, in serve_forever\n",
      "    ready = selector.select(poll_interval)\n",
      "  File \"/Users/hari/anaconda/lib/python3.5/selectors.py\", line 376, in select\n",
      "    fd_event_list = self._poll.poll(timeout)\n",
      "KeyboardInterrupt\n"
     ]
    }
   ],
   "source": [
    "!python pong-server.py localhost:1337"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Congratulations! We have depolyed our first model to Clipper! Let's take a look at it by clicking http://localhost:3000/pong/ and pressing 1 to start the game."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2: Training a better model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you probably noticed, the random-guessing policy did not perform well at all. In order to train a better model, we are going to use imitation learning. Let's play the game again, this time with 2 actual players, and we will collect data on how you play the game to train our model! "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Go to http://localhost:3000/pong/ and press 2. Find someone next to you and play pong against them!!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Part to collect data into a output.csv --> currently doing this in really hacky way to just get it to work, but trying to figure out better solution</b>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have our data, lets train a new model! First, run the cell below to clean the data and format it for scikit-learn's LogisticRegression model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>paddle_y</th>\n",
       "      <th>ball_x</th>\n",
       "      <th>ball_y</th>\n",
       "      <th>ball_dx</th>\n",
       "      <th>ball_dy</th>\n",
       "      <th>x_prev</th>\n",
       "      <th>y_prev</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.6576</td>\n",
       "      <td>0.416920</td>\n",
       "      <td>0.606838</td>\n",
       "      <td>0.335032</td>\n",
       "      <td>0.335032</td>\n",
       "      <td>0.400188</td>\n",
       "      <td>0.590107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.6774</td>\n",
       "      <td>0.433692</td>\n",
       "      <td>0.623610</td>\n",
       "      <td>0.335832</td>\n",
       "      <td>0.335832</td>\n",
       "      <td>0.416920</td>\n",
       "      <td>0.606838</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0.7170</td>\n",
       "      <td>0.467355</td>\n",
       "      <td>0.657273</td>\n",
       "      <td>0.337432</td>\n",
       "      <td>0.337432</td>\n",
       "      <td>0.449157</td>\n",
       "      <td>0.639075</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0.7566</td>\n",
       "      <td>0.501178</td>\n",
       "      <td>0.691096</td>\n",
       "      <td>0.339032</td>\n",
       "      <td>0.339032</td>\n",
       "      <td>0.484246</td>\n",
       "      <td>0.674165</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0.7764</td>\n",
       "      <td>0.518150</td>\n",
       "      <td>0.708068</td>\n",
       "      <td>0.339832</td>\n",
       "      <td>0.339832</td>\n",
       "      <td>0.501178</td>\n",
       "      <td>0.691096</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   label  paddle_y    ball_x    ball_y   ball_dx   ball_dy    x_prev    y_prev\n",
       "0      1    0.6576  0.416920  0.606838  0.335032  0.335032  0.400188  0.590107\n",
       "1      1    0.6774  0.433692  0.623610  0.335832  0.335832  0.416920  0.606838\n",
       "2      1    0.7170  0.467355  0.657273  0.337432  0.337432  0.449157  0.639075\n",
       "3      1    0.7566  0.501178  0.691096  0.339032  0.339032  0.484246  0.674165\n",
       "4      1    0.7764  0.518150  0.708068  0.339832  0.339832  0.501178  0.691096"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Read data into table\n",
    "data_table= Table.read_table('out.csv')\n",
    "\n",
    "#Convert labels into numeric values\n",
    "def convert_label(label):\n",
    "    if(label==\"down\"):\n",
    "        return 1\n",
    "    elif(label==\"up\"):\n",
    "        return 2\n",
    "    else:\n",
    "        return 0\n",
    "data_table_2 = data_table.with_column(\"label\", data_table.apply(convert_label, 0))\n",
    "\n",
    "#Scale our data down\n",
    "final_table = Table().with_columns(\"label\", data_table.apply(convert_label, 0),\n",
    "                                  \"paddle_y\", data_table.column(1)/500.0,\n",
    "                                  \"ball_x\", data_table.column(2)/500.0,\n",
    "                                  \"ball_y\", data_table.column(3)/500.0,\n",
    "                                  \"ball_dx\", data_table.column(4)/500.0,\n",
    "                                  \"ball_dy\", data_table.column(5)/500.0,\n",
    "                                  \"x_prev\", data_table.column(6)/500.0,\n",
    "                                  \"y_prev\", data_table.column(7)/500.0)\n",
    "data_df = final_table.to_df()\n",
    "data_df.take(np.arange(5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are going to use the data to train a scikit-learn Logistic Regression model. You can read more about the particular model <a url=\"http://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html\">here</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels = data_df['label']\n",
    "training_data= data_df.drop(['label'], axis=1)\n",
    "\n",
    "model = linear_model.LogisticRegression()\n",
    "model.fit(training_data, labels)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 3: Deploying updated model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have an updated model, we can deploy that model onto Clipper. Once the system realizes there is a new version of the model, it will automatically switch to serving the newer version of the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"update_model.png\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Image(url= \"update_model.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "18-09-05:22:09:03 INFO     [deployer_utils.py:44] Saving function to /tmp/clipper/tmp7_o4vxso\n",
      "18-09-05:22:09:03 INFO     [deployer_utils.py:54] Serialized and supplied predict function\n",
      "18-09-05:22:09:03 INFO     [python.py:192] Python closure saved\n",
      "18-09-05:22:09:03 INFO     [python.py:202] Using Python 3.5 base image\n",
      "18-09-05:22:09:03 INFO     [clipper_admin.py:452] Building model Docker image with model data from /tmp/clipper/tmp7_o4vxso\n",
      "18-09-05:22:09:52 INFO     [clipper_admin.py:456] {'stream': 'Step 1/3 : FROM clipper/python35-closure-container:0.3.0'}\n",
      "18-09-05:22:09:52 INFO     [clipper_admin.py:456] {'stream': '\\n'}\n",
      "18-09-05:22:09:52 INFO     [clipper_admin.py:456] {'stream': ' ---> 1fc910c1ed28\\n'}\n",
      "18-09-05:22:09:52 INFO     [clipper_admin.py:456] {'stream': 'Step 2/3 : COPY /tmp/clipper/tmp7_o4vxso /model/'}\n",
      "18-09-05:22:09:52 INFO     [clipper_admin.py:456] {'stream': '\\n'}\n",
      "18-09-05:22:09:52 INFO     [clipper_admin.py:456] {'stream': ' ---> de1022770b73\\n'}\n",
      "18-09-05:22:09:52 INFO     [clipper_admin.py:456] {'stream': 'Step 3/3 : RUN apt-get -y install build-essential && pip install numpy scipy pandas datascience sklearn'}\n",
      "18-09-05:22:09:52 INFO     [clipper_admin.py:456] {'stream': '\\n'}\n",
      "18-09-05:22:09:52 INFO     [clipper_admin.py:456] {'stream': ' ---> Running in af42e8430790\\n'}\n",
      "18-09-05:22:09:52 INFO     [clipper_admin.py:456] {'stream': 'Reading package lists...'}\n",
      "18-09-05:22:09:52 INFO     [clipper_admin.py:456] {'stream': '\\n'}\n",
      "18-09-05:22:09:52 INFO     [clipper_admin.py:456] {'stream': 'Building dependency tree...'}\n",
      "18-09-05:22:09:52 INFO     [clipper_admin.py:456] {'stream': '\\n'}\n",
      "18-09-05:22:09:52 INFO     [clipper_admin.py:456] {'stream': 'Reading state information...'}\n",
      "18-09-05:22:09:52 INFO     [clipper_admin.py:456] {'stream': '\\n'}\n",
      "18-09-05:22:09:52 INFO     [clipper_admin.py:456] {'stream': 'build-essential is already the newest version.\\n0 upgraded, 0 newly installed, 0 to remove and 3 not upgraded.\\n'}\n",
      "18-09-05:22:09:52 INFO     [clipper_admin.py:456] {'stream': 'Requirement already satisfied: numpy in /usr/local/lib/python3.5/site-packages\\n'}\n",
      "18-09-05:22:09:52 INFO     [clipper_admin.py:456] {'stream': 'Collecting scipy\\n'}\n",
      "18-09-05:22:09:52 INFO     [clipper_admin.py:456] {'stream': '  Downloading https://files.pythonhosted.org/packages/cd/32/5196b64476bd41d596a8aba43506e2403e019c90e1a3dfc21d51b83db5a6/scipy-1.1.0-cp35-cp35m-manylinux1_x86_64.whl (33.1MB)\\n'}\n",
      "18-09-05:22:09:52 INFO     [clipper_admin.py:456] {'stream': 'Collecting pandas\\n'}\n",
      "18-09-05:22:09:52 INFO     [clipper_admin.py:456] {'stream': '  Downloading https://files.pythonhosted.org/packages/5d/d4/6e9c56a561f1d27407bf29318ca43f36ccaa289271b805a30034eb3a8ec4/pandas-0.23.4-cp35-cp35m-manylinux1_x86_64.whl (8.7MB)\\n'}\n",
      "18-09-05:22:09:52 INFO     [clipper_admin.py:456] {'stream': 'Collecting datascience\\n'}\n",
      "18-09-05:22:09:52 INFO     [clipper_admin.py:456] {'stream': '  Downloading https://files.pythonhosted.org/packages/35/77/c536ef2618b79264f24ad143f0ec061e21a25485261e81f3736c8c8dda42/datascience-0.10.5.tar.gz (40kB)\\n'}\n",
      "18-09-05:22:09:52 INFO     [clipper_admin.py:456] {'stream': 'Collecting sklearn\\n'}\n",
      "18-09-05:22:09:52 INFO     [clipper_admin.py:456] {'stream': '  Downloading https://files.pythonhosted.org/packages/1e/7a/dbb3be0ce9bd5c8b7e3d87328e79063f8b263b2b1bfa4774cb1147bfcd3f/sklearn-0.0.tar.gz\\n'}\n",
      "18-09-05:22:09:52 INFO     [clipper_admin.py:456] {'stream': 'Requirement already satisfied: python-dateutil>=2.5.0 in /usr/local/lib/python3.5/site-packages (from pandas)\\n'}\n",
      "18-09-05:22:09:52 INFO     [clipper_admin.py:456] {'stream': 'Collecting pytz>=2011k (from pandas)\\n'}\n",
      "18-09-05:22:09:52 INFO     [clipper_admin.py:456] {'stream': '  Downloading https://files.pythonhosted.org/packages/30/4e/27c34b62430286c6d59177a0842ed90dc789ce5d1ed740887653b898779a/pytz-2018.5-py2.py3-none-any.whl (510kB)\\n'}\n",
      "18-09-05:22:09:52 INFO     [clipper_admin.py:456] {'stream': 'Collecting folium==0.2.1 (from datascience)\\n'}\n",
      "18-09-05:22:09:52 INFO     [clipper_admin.py:456] {'stream': '  Downloading https://files.pythonhosted.org/packages/72/dd/75ced7437bfa7cb9a88b96ee0177953062803c3b4cde411a97d98c35adaf/folium-0.2.1.tar.gz (69kB)\\n'}\n",
      "18-09-05:22:09:52 INFO     [clipper_admin.py:456] {'stream': 'Collecting sphinx (from datascience)\\n'}\n",
      "18-09-05:22:09:52 INFO     [clipper_admin.py:456] {'stream': '  Downloading https://files.pythonhosted.org/packages/90/f9/a0babe32c78480994e4f1b93315558f5ed756104054a7029c672a8d77b72/Sphinx-1.7.9-py2.py3-none-any.whl (1.9MB)\\n'}\n",
      "18-09-05:22:09:52 INFO     [clipper_admin.py:456] {'stream': 'Requirement already satisfied: setuptools in /usr/local/lib/python3.5/site-packages (from datascience)\\n'}\n",
      "18-09-05:22:09:52 INFO     [clipper_admin.py:456] {'stream': 'Collecting pytest (from datascience)\\n'}\n",
      "18-09-05:22:09:52 INFO     [clipper_admin.py:456] {'stream': '  Downloading https://files.pythonhosted.org/packages/0e/8c/673d56ebe1c9362ff829acf7e67fd4aba09377d44d80fc7435f1369bfe3a/pytest-3.7.4-py2.py3-none-any.whl (204kB)\\n'}\n",
      "18-09-05:22:09:52 INFO     [clipper_admin.py:456] {'stream': 'Collecting coverage==3.7.1 (from datascience)\\n'}\n",
      "18-09-05:22:09:52 INFO     [clipper_admin.py:456] {'stream': '  Downloading https://files.pythonhosted.org/packages/09/4f/89b06c7fdc09687bca507dc411c342556ef9c5a3b26756137a4878ff19bf/coverage-3.7.1.tar.gz (284kB)\\n'}\n",
      "18-09-05:22:09:52 INFO     [clipper_admin.py:456] {'stream': 'Collecting coveralls==0.5 (from datascience)\\n'}\n",
      "18-09-05:22:09:52 INFO     [clipper_admin.py:456] {'stream': '  Downloading https://files.pythonhosted.org/packages/7d/16/db9bcd676fea5cc45980e24ce66c77f348cf3c750d9c2c7bebd8b8792bf1/coveralls-0.5.zip\\n'}\n",
      "18-09-05:22:09:52 INFO     [clipper_admin.py:456] {'stream': 'Collecting scikit-learn (from sklearn)\\n'}\n",
      "18-09-05:22:09:52 INFO     [clipper_admin.py:456] {'stream': '  Downloading https://files.pythonhosted.org/packages/b6/e2/a1e254a4a4598588d4fe88b45ab88a226c289ecfd0f6c90474eb6a9ea6b3/scikit_learn-0.19.2-cp35-cp35m-manylinux1_x86_64.whl (4.9MB)\\n'}\n",
      "18-09-05:22:09:52 INFO     [clipper_admin.py:456] {'stream': 'Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.5/site-packages (from python-dateutil>=2.5.0->pandas)\\n'}\n",
      "18-09-05:22:09:52 INFO     [clipper_admin.py:456] {'stream': 'Requirement already satisfied: Jinja2 in /usr/local/lib/python3.5/site-packages (from folium==0.2.1->datascience)\\n'}\n",
      "18-09-05:22:09:52 INFO     [clipper_admin.py:456] {'stream': 'Collecting Pygments>=2.0 (from sphinx->datascience)\\n'}\n",
      "18-09-05:22:09:52 INFO     [clipper_admin.py:456] {'stream': '  Downloading https://files.pythonhosted.org/packages/02/ee/b6e02dc6529e82b75bb06823ff7d005b141037cb1416b10c6f00fc419dca/Pygments-2.2.0-py2.py3-none-any.whl (841kB)\\n'}\n",
      "18-09-05:22:09:52 INFO     [clipper_admin.py:456] {'stream': 'Requirement already satisfied: requests>=2.0.0 in /usr/local/lib/python3.5/site-packages (from sphinx->datascience)\\n'}\n",
      "18-09-05:22:09:52 INFO     [clipper_admin.py:456] {'stream': 'Collecting sphinxcontrib-websupport (from sphinx->datascience)\\n'}\n",
      "18-09-05:22:09:52 INFO     [clipper_admin.py:456] {'stream': '  Downloading https://files.pythonhosted.org/packages/52/69/3c2fbdc3702358c5b34ee25e387b24838597ef099761fc9a42c166796e8f/sphinxcontrib_websupport-1.1.0-py2.py3-none-any.whl\\n'}\n",
      "18-09-05:22:09:52 INFO     [clipper_admin.py:456] {'stream': 'Collecting imagesize (from sphinx->datascience)\\n'}\n",
      "18-09-05:22:09:52 INFO     [clipper_admin.py:456] {'stream': '  Downloading https://files.pythonhosted.org/packages/fc/b6/aef66b4c52a6ad6ac18cf6ebc5731ed06d8c9ae4d3b2d9951f261150be67/imagesize-1.1.0-py2.py3-none-any.whl\\n'}\n",
      "18-09-05:22:09:52 INFO     [clipper_admin.py:456] {'stream': 'Collecting docutils>=0.11 (from sphinx->datascience)\\n'}\n",
      "18-09-05:22:09:52 INFO     [clipper_admin.py:456] {'stream': '  Downloading https://files.pythonhosted.org/packages/36/fa/08e9e6e0e3cbd1d362c3bbee8d01d0aedb2155c4ac112b19ef3cae8eed8d/docutils-0.14-py3-none-any.whl (543kB)\\n'}\n",
      "18-09-05:22:09:52 INFO     [clipper_admin.py:456] {'stream': 'Collecting alabaster<0.8,>=0.7 (from sphinx->datascience)\\n'}\n",
      "18-09-05:22:09:52 INFO     [clipper_admin.py:456] {'stream': '  Downloading https://files.pythonhosted.org/packages/6e/71/c3648cc2f675063dbe2d669004a59e4a5120172713a1de3c3b14144d4b31/alabaster-0.7.11-py2.py3-none-any.whl\\n'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "18-09-05:22:09:52 INFO     [clipper_admin.py:456] {'stream': 'Collecting snowballstemmer>=1.1 (from sphinx->datascience)\\n'}\n",
      "18-09-05:22:09:52 INFO     [clipper_admin.py:456] {'stream': '  Downloading https://files.pythonhosted.org/packages/d4/6c/8a935e2c7b54a37714656d753e4187ee0631988184ed50c0cf6476858566/snowballstemmer-1.2.1-py2.py3-none-any.whl (64kB)\\n'}\n",
      "18-09-05:22:09:52 INFO     [clipper_admin.py:456] {'stream': 'Collecting packaging (from sphinx->datascience)\\n'}\n",
      "18-09-05:22:09:52 INFO     [clipper_admin.py:456] {'stream': '  Downloading https://files.pythonhosted.org/packages/ad/c2/b500ea05d5f9f361a562f089fc91f77ed3b4783e13a08a3daf82069b1224/packaging-17.1-py2.py3-none-any.whl\\n'}\n",
      "18-09-05:22:09:52 INFO     [clipper_admin.py:456] {'stream': 'Collecting babel!=2.0,>=1.3 (from sphinx->datascience)\\n'}\n",
      "18-09-05:22:09:52 INFO     [clipper_admin.py:456] {'stream': '  Downloading https://files.pythonhosted.org/packages/b8/ad/c6f60602d3ee3d92fbed87675b6fb6a6f9a38c223343ababdb44ba201f10/Babel-2.6.0-py2.py3-none-any.whl (8.1MB)\\n'}\n",
      "18-09-05:22:09:52 INFO     [clipper_admin.py:456] {'stream': 'Collecting py>=1.5.0 (from pytest->datascience)\\n'}\n",
      "18-09-05:22:09:52 INFO     [clipper_admin.py:456] {'stream': '  Downloading https://files.pythonhosted.org/packages/c8/47/d179b80ab1dc1bfd46a0c87e391be47e6c7ef5831a9c138c5c49d1756288/py-1.6.0-py2.py3-none-any.whl (83kB)\\n'}\n",
      "18-09-05:22:09:52 INFO     [clipper_admin.py:456] {'stream': 'Collecting pluggy>=0.7 (from pytest->datascience)\\n'}\n",
      "18-09-05:22:09:52 INFO     [clipper_admin.py:456] {'stream': '  Downloading https://files.pythonhosted.org/packages/f5/f1/5a93c118663896d83f7bcbfb7f657ce1d0c0d617e6b4a443a53abcc658ca/pluggy-0.7.1-py2.py3-none-any.whl\\n'}\n",
      "18-09-05:22:09:52 INFO     [clipper_admin.py:456] {'stream': 'Collecting more-itertools>=4.0.0 (from pytest->datascience)\\n'}\n",
      "18-09-05:22:09:52 INFO     [clipper_admin.py:456] {'stream': '  Downloading https://files.pythonhosted.org/packages/79/b1/eace304ef66bd7d3d8b2f78cc374b73ca03bc53664d78151e9df3b3996cc/more_itertools-4.3.0-py3-none-any.whl (48kB)\\n'}\n",
      "18-09-05:22:09:52 INFO     [clipper_admin.py:456] {'stream': 'Collecting pathlib2>=2.2.0; python_version < \"3.6\" (from pytest->datascience)\\n'}\n",
      "18-09-05:22:09:52 INFO     [clipper_admin.py:456] {'stream': '  Downloading https://files.pythonhosted.org/packages/66/a7/9f8d84f31728d78beade9b1271ccbfb290c41c1e4dc13dbd4997ad594dcd/pathlib2-2.3.2-py2.py3-none-any.whl\\n'}\n",
      "18-09-05:22:09:52 INFO     [clipper_admin.py:456] {'stream': 'Collecting attrs>=17.4.0 (from pytest->datascience)\\n'}\n",
      "18-09-05:22:09:52 INFO     [clipper_admin.py:456] {'stream': '  Downloading https://files.pythonhosted.org/packages/3a/e1/5f9023cc983f1a628a8c2fd051ad19e76ff7b142a0faf329336f9a62a514/attrs-18.2.0-py2.py3-none-any.whl\\n'}\n",
      "18-09-05:22:09:52 INFO     [clipper_admin.py:456] {'stream': 'Collecting atomicwrites>=1.0 (from pytest->datascience)\\n'}\n",
      "18-09-05:22:09:52 INFO     [clipper_admin.py:456] {'stream': '  Downloading https://files.pythonhosted.org/packages/3a/9a/9d878f8d885706e2530402de6417141129a943802c084238914fa6798d97/atomicwrites-1.2.1-py2.py3-none-any.whl\\n'}\n",
      "18-09-05:22:09:52 INFO     [clipper_admin.py:456] {'stream': 'Requirement already satisfied: PyYAML>=3.10 in /usr/local/lib/python3.5/site-packages (from coveralls==0.5->datascience)\\n'}\n",
      "18-09-05:22:09:52 INFO     [clipper_admin.py:456] {'stream': 'Collecting docopt>=0.6.1 (from coveralls==0.5->datascience)\\n'}\n",
      "18-09-05:22:09:52 INFO     [clipper_admin.py:456] {'stream': '  Downloading https://files.pythonhosted.org/packages/a2/55/8f8cab2afd404cf578136ef2cc5dfb50baa1761b68c9da1fb1e4eed343c9/docopt-0.6.2.tar.gz\\n'}\n",
      "18-09-05:22:09:52 INFO     [clipper_admin.py:456] {'stream': 'Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.5/site-packages (from Jinja2->folium==0.2.1->datascience)\\n'}\n",
      "18-09-05:22:09:52 INFO     [clipper_admin.py:456] {'stream': 'Requirement already satisfied: urllib3<1.23,>=1.21.1 in /usr/local/lib/python3.5/site-packages (from requests>=2.0.0->sphinx->datascience)\\n'}\n",
      "18-09-05:22:09:52 INFO     [clipper_admin.py:456] {'stream': 'Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.5/site-packages (from requests>=2.0.0->sphinx->datascience)\\n'}\n",
      "18-09-05:22:09:52 INFO     [clipper_admin.py:456] {'stream': 'Requirement already satisfied: idna<2.7,>=2.5 in /usr/local/lib/python3.5/site-packages (from requests>=2.0.0->sphinx->datascience)\\n'}\n",
      "18-09-05:22:09:52 INFO     [clipper_admin.py:456] {'stream': 'Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.5/site-packages (from requests>=2.0.0->sphinx->datascience)\\n'}\n",
      "18-09-05:22:09:52 INFO     [clipper_admin.py:456] {'stream': 'Collecting pyparsing>=2.0.2 (from packaging->sphinx->datascience)\\n'}\n",
      "18-09-05:22:09:52 INFO     [clipper_admin.py:456] {'stream': '  Downloading https://files.pythonhosted.org/packages/6a/8a/718fd7d3458f9fab8e67186b00abdd345b639976bc7fb3ae722e1b026a50/pyparsing-2.2.0-py2.py3-none-any.whl (56kB)\\n'}\n",
      "18-09-05:22:09:52 INFO     [clipper_admin.py:456] {'stream': 'Building wheels for collected packages: datascience, sklearn, folium, coverage, coveralls, docopt\\n'}\n",
      "18-09-05:22:09:52 INFO     [clipper_admin.py:456] {'stream': '  Running setup.py bdist_wheel for datascience: started\\n'}\n",
      "18-09-05:22:09:52 INFO     [clipper_admin.py:456] {'stream': \"  Running setup.py bdist_wheel for datascience: finished with status 'done'\\n\"}\n",
      "18-09-05:22:09:52 INFO     [clipper_admin.py:456] {'stream': '  Stored in directory: /root/.cache/pip/wheels/30/ef/47/60a5019f851898fac2556369ee03ca0384627f5125e1f7b083\\n'}\n",
      "18-09-05:22:09:52 INFO     [clipper_admin.py:456] {'stream': '  Running setup.py bdist_wheel for sklearn: started\\n'}\n",
      "18-09-05:22:09:52 INFO     [clipper_admin.py:456] {'stream': \"  Running setup.py bdist_wheel for sklearn: finished with status 'done'\\n\"}\n",
      "18-09-05:22:09:52 INFO     [clipper_admin.py:456] {'stream': '  Stored in directory: /root/.cache/pip/wheels/76/03/bb/589d421d27431bcd2c6da284d5f2286c8e3b2ea3cf1594c074\\n'}\n",
      "18-09-05:22:09:52 INFO     [clipper_admin.py:456] {'stream': '  Running setup.py bdist_wheel for folium: started\\n'}\n",
      "18-09-05:22:09:52 INFO     [clipper_admin.py:456] {'stream': \"  Running setup.py bdist_wheel for folium: finished with status 'done'\\n\"}\n",
      "18-09-05:22:09:52 INFO     [clipper_admin.py:456] {'stream': '  Stored in directory: /root/.cache/pip/wheels/b8/09/f0/52d2ef419c2aaf4fb149f92a33e0008bdce7ae816f0dd8f0c5\\n'}\n",
      "18-09-05:22:09:52 INFO     [clipper_admin.py:456] {'stream': '  Running setup.py bdist_wheel for coverage: started\\n'}\n",
      "18-09-05:22:09:52 INFO     [clipper_admin.py:456] {'stream': \"  Running setup.py bdist_wheel for coverage: finished with status 'done'\\n\"}\n",
      "18-09-05:22:09:52 INFO     [clipper_admin.py:456] {'stream': '  Stored in directory: /root/.cache/pip/wheels/68/58/66/f1fc9afad272df0df0fa38cdef34ee2d5d8d6a85f4eb5acab5\\n'}\n",
      "18-09-05:22:09:52 INFO     [clipper_admin.py:456] {'stream': '  Running setup.py bdist_wheel for coveralls: started\\n'}\n",
      "18-09-05:22:09:52 INFO     [clipper_admin.py:456] {'stream': \"  Running setup.py bdist_wheel for coveralls: finished with status 'done'\\n\"}\n",
      "18-09-05:22:09:52 INFO     [clipper_admin.py:456] {'stream': '  Stored in directory: /root/.cache/pip/wheels/50/54/3b/b62b1288fa80808256abccca3b8fff97ed694404c4f5fe2646\\n'}\n",
      "18-09-05:22:09:52 INFO     [clipper_admin.py:456] {'stream': '  Running setup.py bdist_wheel for docopt: started\\n'}\n",
      "18-09-05:22:09:52 INFO     [clipper_admin.py:456] {'stream': \"  Running setup.py bdist_wheel for docopt: finished with status 'done'\\n\"}\n",
      "18-09-05:22:09:52 INFO     [clipper_admin.py:456] {'stream': '  Stored in directory: /root/.cache/pip/wheels/9b/04/dd/7daf4150b6d9b12949298737de9431a324d4b797ffd63f526e\\nSuccessfully built datascience sklearn folium coverage coveralls docopt\\nInstalling collected packages: scipy, pytz, pandas, folium, Pygments, sphinxcontrib-websupport, imagesize, docutils, alabaster, snowballstemmer, pyparsing, packaging, babel, sphinx, py, pluggy, more-itertools, pathlib2, attrs, atomicwrites, pytest, coverage, docopt, coveralls, datascience, scikit-learn, sklearn\\n'}\n",
      "18-09-05:22:09:52 INFO     [clipper_admin.py:456] {'stream': 'Successfully installed Pygments-2.2.0 alabaster-0.7.11 atomicwrites-1.2.1 attrs-18.2.0 babel-2.6.0 coverage-3.7.1 coveralls-0.5 datascience-0.10.5 docopt-0.6.2 docutils-0.14 folium-0.2.1 imagesize-1.1.0 more-itertools-4.3.0 packaging-17.1 pandas-0.23.4 pathlib2-2.3.2 pluggy-0.7.1 py-1.6.0 pyparsing-2.2.0 pytest-3.7.4 pytz-2018.5 scikit-learn-0.19.2 scipy-1.1.0 sklearn-0.0 snowballstemmer-1.2.1 sphinx-1.7.9 sphinxcontrib-websupport-1.1.0\\n'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "18-09-05:22:09:52 INFO     [clipper_admin.py:456] {'stream': \"\\x1b[91mYou are using pip version 9.0.3, however version 18.0 is available.\\nYou should consider upgrading via the 'pip install --upgrade pip' command.\\n\\x1b[0m\"}\n",
      "18-09-05:22:09:52 INFO     [clipper_admin.py:456] {'stream': ' ---> 37f52cefca5f\\n'}\n",
      "18-09-05:22:09:52 INFO     [clipper_admin.py:456] {'aux': {'ID': 'sha256:37f52cefca5fb55a7660b2fdbb34930224a875bf462b4c71b96db1a5e278125e'}}\n",
      "18-09-05:22:09:52 INFO     [clipper_admin.py:456] {'stream': 'Successfully built 37f52cefca5f\\n'}\n",
      "18-09-05:22:09:52 INFO     [clipper_admin.py:456] {'stream': 'Successfully tagged pong:3\\n'}\n",
      "18-09-05:22:09:52 INFO     [clipper_admin.py:458] Pushing model Docker image to pong:3\n",
      "18-09-05:22:09:53 INFO     [docker_container_manager.py:257] Found 0 replicas for pong:3. Adding 1\n",
      "18-09-05:22:10:00 INFO     [clipper_admin.py:635] Successfully registered model pong:3\n",
      "18-09-05:22:10:00 INFO     [clipper_admin.py:553] Done deploying model pong:3.\n"
     ]
    }
   ],
   "source": [
    "def predict(inputs):\n",
    "    # model.predict returns a list of predictions\n",
    "    preds = model.predict(inputs)\n",
    "    return [str(p) for p in preds]\n",
    "\n",
    "py_deployer.deploy_python_closure(clipper_conn, name=\"pong\", version=3, input_type=\"doubles\", func=predict, pkgs_to_install=[\"numpy\",\"scipy\", \"pandas\", \"datascience\", \"sklearn\"])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You may notice that it seems like we only deployed the predict function to Clipper. However, Clipper will track the dependencies that the model in the predict function uses and include them in the model Docker container as dependencies. You can take a look at the logs above to see the Docker container downloading said dependencies.\n",
    "\n",
    "Let's run our server again (or refresh the page if you haven't stopped the server previously)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18-09-05:22:12:10 INFO     [pong-server.py:109] Starting Pong Server on localhost:3000\n",
      "^C\n",
      "Traceback (most recent call last):\n",
      "  File \"pong-server.py\", line 117, in <module>\n",
      "    run(clipper_addr)\n",
      "  File \"pong-server.py\", line 112, in run\n",
      "    server.serve_forever()\n",
      "  File \"/Users/hari/anaconda/lib/python3.5/socketserver.py\", line 232, in serve_forever\n",
      "    ready = selector.select(poll_interval)\n",
      "  File \"/Users/hari/anaconda/lib/python3.5/selectors.py\", line 376, in select\n",
      "    fd_event_list = self._poll.poll(timeout)\n",
      "KeyboardInterrupt\n"
     ]
    }
   ],
   "source": [
    "!python pong-server.py localhost:1337"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cool points here:\n",
    "1. We never restarted the pong server, but our code seamlessly switches to serving the updated model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Just as a recap, here's what we did today:\n",
    "\n",
    "1. Deployed an initial random policy to Clipper and served predictions\n",
    "2. Trained a new model with data that you generated while playing pong\n",
    "3. Deployed new version of model and seamlessly switch the model being served\n",
    "\n",
    "By doing so, we've explored the following Clipper features:\n",
    "\n",
    "1. Deploy models trained in your choice of framework to Clipper with a few lines of code by using an existing model container or writing your own\n",
    "2. Easily update or roll back models in running applications\n",
    "3. Run each model in a separate Docker container for simple cluster management and resource allocation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18-09-05:22:13:12 INFO     [clipper_admin.py:1258] Stopped all Clipper cluster and all model containers\r\n"
     ]
    }
   ],
   "source": [
    "!python stop_c.py\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TO-DOS\n",
    "\n",
    "\n",
    "1. Fix copy on tutorial\n",
    "2. Package dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:anaconda]",
   "language": "python",
   "name": "conda-env-anaconda-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
